[
  {
    "objectID": "method_package.html",
    "href": "method_package.html",
    "title": "Content",
    "section": "",
    "text": "The slides contain the lecture slides for the first half of the semester.\n\nSlides 1\nSlides 2\nSlides 3\nSlides 4\nSlides 5"
  },
  {
    "objectID": "method_package.html#freaky-friday",
    "href": "method_package.html#freaky-friday",
    "title": "Content",
    "section": "Freaky Friday",
    "text": "Freaky Friday\nContains an attempt at a replication from downloading the data to analyzing for Dellavigna and Pollet (2009).\nIntroduction to the Replication"
  },
  {
    "objectID": "auxilary/introduction_to_rstudio_for_accfin.html",
    "href": "auxilary/introduction_to_rstudio_for_accfin.html",
    "title": "Introduction to Rstudio for Accounting and Finance",
    "section": "",
    "text": "This setup code loads a package, here, that helps to navigate the folder structure in which I will create files. The tidyverse package is the main package, we will use to manipulate datasets. There are other ways to program in R. I think that to start of the tidyverse way of looking at data is quite intuitive and it is very well supported. The intuition and how quickly you can do meaningful things will hopefully be clear by the end of this document."
  },
  {
    "objectID": "auxilary/introduction_to_rstudio_for_accfin.html#with-the-tidyverse",
    "href": "auxilary/introduction_to_rstudio_for_accfin.html#with-the-tidyverse",
    "title": "Introduction to Rstudio for Accounting and Finance",
    "section": "With the tidyverse",
    "text": "With the tidyverse\n\nus_comp <- readRDS(here(\"data\", \"us-compensation-new.RDS\"))\nglimpse(us_comp)\n\nRows: 21,855\nColumns: 22\n$ year                    <dbl> 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018…\n$ gvkey                   <chr> \"001004\", \"001004\", \"001004\", \"001004\", \"00100…\n$ cusip                   <chr> \"36110\", \"36110\", \"36110\", \"36110\", \"36110\", \"…\n$ exec_fullname           <chr> \"David P. Storch\", \"David P. Storch\", \"David P…\n$ coname                  <chr> \"AAR CORP\", \"AAR CORP\", \"AAR CORP\", \"AAR CORP\"…\n$ ceoann                  <chr> \"CEO\", \"CEO\", \"CEO\", \"CEO\", \"CEO\", \"CEO\", \"CEO…\n$ execid                  <chr> \"09249\", \"09249\", \"09249\", \"09249\", \"09249\", \"…\n$ bonus                   <dbl> 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.00…\n$ salary                  <dbl> 867.000, 877.838, 906.449, 906.449, 755.250, 8…\n$ stock_awards_fv         <dbl> 2664.745, 619.200, 1342.704, 1695.200, 1150.50…\n$ stock_unvest_val        <dbl> 4227.273, 6018.000, 4244.165, 4103.283, 1334.0…\n$ eip_unearn_num          <dbl> 32.681, 56.681, 66.929, 83.415, 91.969, 157.96…\n$ eip_unearn_val          <dbl> 393.806, 1137.021, 1626.375, 2464.079, 2244.96…\n$ option_awards           <dbl> 578.460, 695.520, 1622.016, 0.000, 1150.500, 1…\n$ option_awards_blk_value <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ option_awards_num       <dbl> 49.022, 144.000, 158.400, 0.000, 153.810, 225.…\n$ tdc1                    <dbl> 5786.400, 4182.832, 5247.779, 5234.648, 4674.4…\n$ tdc2                    <dbl> 6105.117, 3487.312, 3809.626, 10428.375, 3523.…\n$ shrown_tot_pct          <dbl> 2.964, 2.893, 3.444, 3.877, 4.597, 5.417, 3.71…\n$ becameceo               <date> 1996-10-09, 1996-10-09, 1996-10-09, 1996-10-0…\n$ joined_co               <date> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ reason                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\nfilter(us_comp, gvkey == \"001004\")\n\n# A tibble: 11 × 22\n    year gvkey  cusip exec_f…¹ coname ceoann execid bonus salary stock…² stock…³\n   <dbl> <chr>  <chr> <chr>    <chr>  <chr>  <chr>  <dbl>  <dbl>   <dbl>   <dbl>\n 1  2011 001004 36110 David P… AAR C… CEO    09249      0   867    2665.  4227. \n 2  2012 001004 36110 David P… AAR C… CEO    09249      0   878.    619.  6018  \n 3  2013 001004 36110 David P… AAR C… CEO    09249      0   906.   1343.  4244. \n 4  2014 001004 36110 David P… AAR C… CEO    09249      0   906.   1695.  4103. \n 5  2015 001004 36110 David P… AAR C… CEO    09249      0   755.   1150.  1334. \n 6  2016 001004 36110 David P… AAR C… CEO    09249      0   835    1584   1029. \n 7  2017 001004 36110 David P… AAR C… CEO    09249      0   941    1692.   845. \n 8  2018 001004 36110 John Mc… AAR C… CEO    48195      0   750    1125.    30.1\n 9  2019 001004 36110 John Mc… AAR C… CEO    48195      0   801.   1300.     0  \n10  2020 001004 36110 John Mc… AAR C… CEO    48195      0   781.      0      0  \n11  2021 001004 36110 John Mc… AAR C… CEO    48195      0   925    8302.  7361. \n# … with 11 more variables: eip_unearn_num <dbl>, eip_unearn_val <dbl>,\n#   option_awards <dbl>, option_awards_blk_value <dbl>,\n#   option_awards_num <dbl>, tdc1 <dbl>, tdc2 <dbl>, shrown_tot_pct <dbl>,\n#   becameceo <date>, joined_co <date>, reason <chr>, and abbreviated variable\n#   names ¹​exec_fullname, ²​stock_awards_fv, ³​stock_unvest_val\n\n\n\nfilter(us_comp, bonus == 0, year == 2012)\n\n# A tibble: 1,669 × 22\n    year gvkey  cusip  exec_…¹ coname ceoann execid bonus salary stock…² stock…³\n   <dbl> <chr>  <chr>  <chr>   <chr>  <chr>  <chr>  <dbl>  <dbl>   <dbl>   <dbl>\n 1  2012 001004 36110  David … AAR C… CEO    09249      0   878.    619.   6018 \n 2  2012 001045 02376… Thomas… AMERI… CEO    26059      0   618.      0     310.\n 3  2012 001075 72348… Donald… PINNA… CEO    05835      0  1146    7100.   9056.\n 4  2012 001076 74319… Ronald… PROG … CEO    00283      0   850    2489    3210.\n 5  2012 001078 282410 Miles … ABBOT… CEO    14300      0  1900    9429.      0 \n 6  2012 001094 444610 Albert… ACETO… CEO    46204      0   626.      0     322.\n 7  2012 001161 790310 Rory P… ADVAN… CEO    42390      0  1000.   3745.   1710.\n 8  2012 001177 00817… Mark T… AETNA… CEO    31029      0   977.  11125.   9977.\n 9  2012 001209 915810 John E… AIR P… CEO    27315      0  1200    3600.  10452.\n10  2012 001230 11659… Bradle… ALASK… CEO    21308      0   420.   2579.   1689.\n# … with 1,659 more rows, 11 more variables: eip_unearn_num <dbl>,\n#   eip_unearn_val <dbl>, option_awards <dbl>, option_awards_blk_value <dbl>,\n#   option_awards_num <dbl>, tdc1 <dbl>, tdc2 <dbl>, shrown_tot_pct <dbl>,\n#   becameceo <date>, joined_co <date>, reason <chr>, and abbreviated variable\n#   names ¹​exec_fullname, ²​stock_awards_fv, ³​stock_unvest_val"
  },
  {
    "objectID": "auxilary/introduction_to_rstudio_for_accfin.html#a-gamestop-to-introduce-the-pipe",
    "href": "auxilary/introduction_to_rstudio_for_accfin.html#a-gamestop-to-introduce-the-pipe",
    "title": "Introduction to Rstudio for Accounting and Finance",
    "section": "A Gamestop to introduce the pipe",
    "text": "A Gamestop to introduce the pipe\n\nLook for any company where “gamestop” is in the name of the company.\nLook for the gvkey of Gamestop. Then use filter with exactly that key.\n\n\nfilter(us_comp, str_detect(tolower(coname),\n                           \"gamestop\"))\n\n# A tibble: 11 × 22\n    year gvkey  cusip  exec_…¹ coname ceoann execid bonus salary stock…² stock…³\n   <dbl> <chr>  <chr>  <chr>   <chr>  <chr>  <chr>  <dbl>  <dbl>   <dbl>   <dbl>\n 1  2011 145049 36467… J. Pau… GAMES… CEO    35719  2254.  1028.   1042.   2408.\n 2  2012 145049 36467… J. Pau… GAMES… CEO    35719  1515   1050.   7164.   3573.\n 3  2013 145049 36467… J. Pau… GAMES… CEO    35719   975   1059.      0    4773.\n 4  2014 145049 36467… J. Pau… GAMES… CEO    35719     0   1201.      0    4464.\n 5  2015 145049 36467… J. Pau… GAMES… CEO    35719     0   1247.   5002.   3381.\n 6  2016 145049 36467… J. Pau… GAMES… CEO    35719     0   1285.   4500.   3281.\n 7  2017 145049 36467… J. Pau… GAMES… CEO    35719     0   1293.   4500.   3135.\n 8  2018 145049 36467… Shane … GAMES… CEO    56940    25    963.   1500.   1184.\n 9  2019 145049 36467… George… GAMES… CEO    46080   150    846.  10500.   2255.\n10  2020 145049 36467… George… GAMES… CEO    46080     0   1005.   6120. 428003.\n11  2021 145049 36467… Matthe… GAMES… CEO    61979  1595.   115.  14852.   7116.\n# … with 11 more variables: eip_unearn_num <dbl>, eip_unearn_val <dbl>,\n#   option_awards <dbl>, option_awards_blk_value <dbl>,\n#   option_awards_num <dbl>, tdc1 <dbl>, tdc2 <dbl>, shrown_tot_pct <dbl>,\n#   becameceo <date>, joined_co <date>, reason <chr>, and abbreviated variable\n#   names ¹​exec_fullname, ²​stock_awards_fv, ³​stock_unvest_val\n\nfilter(us_comp, gvkey == \"145049\")\n\n# A tibble: 11 × 22\n    year gvkey  cusip  exec_…¹ coname ceoann execid bonus salary stock…² stock…³\n   <dbl> <chr>  <chr>  <chr>   <chr>  <chr>  <chr>  <dbl>  <dbl>   <dbl>   <dbl>\n 1  2011 145049 36467… J. Pau… GAMES… CEO    35719  2254.  1028.   1042.   2408.\n 2  2012 145049 36467… J. Pau… GAMES… CEO    35719  1515   1050.   7164.   3573.\n 3  2013 145049 36467… J. Pau… GAMES… CEO    35719   975   1059.      0    4773.\n 4  2014 145049 36467… J. Pau… GAMES… CEO    35719     0   1201.      0    4464.\n 5  2015 145049 36467… J. Pau… GAMES… CEO    35719     0   1247.   5002.   3381.\n 6  2016 145049 36467… J. Pau… GAMES… CEO    35719     0   1285.   4500.   3281.\n 7  2017 145049 36467… J. Pau… GAMES… CEO    35719     0   1293.   4500.   3135.\n 8  2018 145049 36467… Shane … GAMES… CEO    56940    25    963.   1500.   1184.\n 9  2019 145049 36467… George… GAMES… CEO    46080   150    846.  10500.   2255.\n10  2020 145049 36467… George… GAMES… CEO    46080     0   1005.   6120. 428003.\n11  2021 145049 36467… Matthe… GAMES… CEO    61979  1595.   115.  14852.   7116.\n# … with 11 more variables: eip_unearn_num <dbl>, eip_unearn_val <dbl>,\n#   option_awards <dbl>, option_awards_blk_value <dbl>,\n#   option_awards_num <dbl>, tdc1 <dbl>, tdc2 <dbl>, shrown_tot_pct <dbl>,\n#   becameceo <date>, joined_co <date>, reason <chr>, and abbreviated variable\n#   names ¹​exec_fullname, ²​stock_awards_fv, ³​stock_unvest_val"
  },
  {
    "objectID": "auxilary/introduction_to_rstudio_for_accfin.html#moving-on",
    "href": "auxilary/introduction_to_rstudio_for_accfin.html#moving-on",
    "title": "Introduction to Rstudio for Accounting and Finance",
    "section": "Moving on",
    "text": "Moving on\n\nselect(us_comp, year, coname, bonus, salary, total = tdc1)\n\n# A tibble: 21,855 × 5\n    year coname   bonus salary total\n   <dbl> <chr>    <dbl>  <dbl> <dbl>\n 1  2011 AAR CORP     0   867  5786.\n 2  2012 AAR CORP     0   878. 4183.\n 3  2013 AAR CORP     0   906. 5248.\n 4  2014 AAR CORP     0   906. 5235.\n 5  2015 AAR CORP     0   755. 4674.\n 6  2016 AAR CORP     0   835  6073.\n 7  2017 AAR CORP     0   941  6284.\n 8  2018 AAR CORP     0   750  3344.\n 9  2019 AAR CORP     0   801. 4736.\n10  2020 AAR CORP     0   781. 4123.\n# … with 21,845 more rows\n\n\nWe first build up the dataset with select and mutate and the pipe %>%. When we are satisfied with the result, we can save the dataset as an R object with the name us_comp_small.\n\nus_comp_small <-\n  select(us_comp, year, coname, bonus,\n       salary, total = tdc1) %>%\n    mutate(salary_percentage = salary/total)\nprint(us_comp_small)\n\n# A tibble: 21,855 × 6\n    year coname   bonus salary total salary_percentage\n   <dbl> <chr>    <dbl>  <dbl> <dbl>             <dbl>\n 1  2011 AAR CORP     0   867  5786.             0.150\n 2  2012 AAR CORP     0   878. 4183.             0.210\n 3  2013 AAR CORP     0   906. 5248.             0.173\n 4  2014 AAR CORP     0   906. 5235.             0.173\n 5  2015 AAR CORP     0   755. 4674.             0.162\n 6  2016 AAR CORP     0   835  6073.             0.138\n 7  2017 AAR CORP     0   941  6284.             0.150\n 8  2018 AAR CORP     0   750  3344.             0.224\n 9  2019 AAR CORP     0   801. 4736.             0.169\n10  2020 AAR CORP     0   781. 4123.             0.189\n# … with 21,845 more rows"
  },
  {
    "objectID": "auxilary/introduction_to_rstudio_for_accfin.html#quick-descriptive-statistics",
    "href": "auxilary/introduction_to_rstudio_for_accfin.html#quick-descriptive-statistics",
    "title": "Introduction to Rstudio for Accounting and Finance",
    "section": "Quick descriptive statistics",
    "text": "Quick descriptive statistics\n\ngroup_by(us_comp, gvkey) %>%\n    summarise(N = n(), N_CEO = n_distinct(execid),\n              average = mean(salary),\n              sd = sd(salary),\n              med = median(salary),\n              min = min(salary),\n              max = max(salary)) %>%\n    ungroup() %>%\n  filter(med > 1000)\n\n# A tibble: 573 × 8\n   gvkey      N N_CEO average    sd   med   min   max\n   <chr>  <int> <int>   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 001075    11     2   1230. 109.  1240  1091  1395 \n 2 001078    11     2   1814. 214.  1900  1298. 1973.\n 3 001161    11     3    944. 146.  1000.  566. 1096.\n 4 001209    12     2   1239. 131.  1200   905. 1402.\n 5 001274    11     1   1082. 101.  1030  1000  1250 \n 6 001300    11     2   1716. 159.  1800  1415. 1890 \n 7 001380    11     1   1500    0   1500  1500  1500 \n 8 001440    11     2   1324. 176.  1325.  903. 1522.\n 9 001447    11     2   1821. 257.  2000  1488. 2038.\n10 001449    11     1   1437.  12.7 1441. 1399. 1441.\n# … with 563 more rows\n\n\n\nsummarise(us_comp, N = n(), N_CEO = n_distinct(execid),\n              average = mean(salary),\n              sd = sd(salary),\n              med = median(salary),\n              min = min(salary),\n              max = max(salary),\n          .by = gvkey) %>%\n  filter(med > 1000)\n\n# A tibble: 573 × 8\n   gvkey      N N_CEO average    sd   med   min   max\n   <chr>  <int> <int>   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 001075    11     2   1230. 109.  1240  1091  1395 \n 2 001078    11     2   1814. 214.  1900  1298. 1973.\n 3 001161    11     3    944. 146.  1000.  566. 1096.\n 4 001209    12     2   1239. 131.  1200   905. 1402.\n 5 001274    11     1   1082. 101.  1030  1000  1250 \n 6 001300    11     2   1716. 159.  1800  1415. 1890 \n 7 001380    11     1   1500    0   1500  1500  1500 \n 8 001440    11     2   1324. 176.  1325.  903. 1522.\n 9 001447    11     2   1821. 257.  2000  1488. 2038.\n10 001449    11     1   1437.  12.7 1441. 1399. 1441.\n# … with 563 more rows"
  },
  {
    "objectID": "slides/slides1.html#how-to-do-empirical-research",
    "href": "slides/slides1.html#how-to-do-empirical-research",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "How to do empirical research",
    "text": "How to do empirical research\n\nThe connection between theory and the observed data\nThe connection between practical knowledge and what you can investigate\nThe appropriate statistical tests and code\n\n\nEmpirical just means that some data in the broadest possible be sense will be collected or generated. The emphasis on the units will be on the practical and statistical issues of the data analysis part of a thesis. The influence will not be on the accounting and finance part of your thesis. The goal is to be relevant to everyone in the unit. This would be a good time to figure out whether students do a study with a more qualitative approach."
  },
  {
    "objectID": "slides/slides1.html#different-modules",
    "href": "slides/slides1.html#different-modules",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Different Modules",
    "text": "Different Modules\n\nThe research process and basic data skills in R (week 1 - 3)\nResearch design (week 4 - 6)\nAdvanced regression (week 7 - 9)\nTime series analysis (10 - 12)\n\n\nAll modules work as stand-alone units and aim to cover a wide range of topics. Not all of them will in the end be relevant for everyone. However, it is probably a good idea to get to know the different statistical methods, their advantages, and disadvantages. Bringing a new methodology to an old topic can be a valuable contribution. Some problems have already been solved in other research streams."
  },
  {
    "objectID": "slides/slides1.html#assessment",
    "href": "slides/slides1.html#assessment",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Assessment",
    "text": "Assessment\n\nNo Exam\n(Almost weekly) Assignments (70%)\n\n\n- Homework: Practical Issues (0%) (3 March)\n- Assignment 1: Theory and Regressions (10%) (10 March)\n- Assignment 2: Regression and control variables (10%) (17 March)\n- Assignment 3: Research Design (10%) (7 April)\n- Assignment 4: Event Study (10%) (28 April)\n- Assignment 5: Machine Learning (10%) (5 May)\n- Assignment 6: Simulation Research Design (20%) (26 May)\n\n\nProposal and presentation (30%)\n\n\n- Pitch (10%) (31 March)\n- Proposal (10%) (12 May)\n- Presentation (10%) (Probably Thursday 20 July)\n\n\nWe want you to (1) do some data analysis and (2) be well prepared to undertake (the data analysis part of) a research project. So we are going to evaluate you by letting you (1) analyse data and (2) prepare your honours thesis."
  },
  {
    "objectID": "slides/slides1.html#the-first-two-weeks",
    "href": "slides/slides1.html#the-first-two-weeks",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "The first two weeks",
    "text": "The first two weeks\nCEO compensation\n\nThis is not my area of expertise!\nI am not a specialist in the topic nor in this type of data analysis. CEO compensation is something that people in finance, accounting, economics, and outside of academia are interested in. The topic is probably the one with the most commonality. I am comforable with these type of economic theories and I am going to stress the role of theory in data analysis a lot. Some of you will have a topic that is at first sight less theory driven or rely more strongly on very specific knowledge about your setting. I am going to try to convince you that it is going to be useful to think about the underlying story that you are testing."
  },
  {
    "objectID": "slides/slides1.html#topic",
    "href": "slides/slides1.html#topic",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Topic",
    "text": "Topic\nCompletely based on Edmans and Gabaix (2016) in Journal of Economic Literature.\n\nThe level of CEO compensation\nCEO incentives\n\n\nI am going to focus on two topics. 1. How high can we expect the total compensation of a CEO to be (compared to other CEOs) based on some simple economic assumptions. Too high CEO compensation is sometimes seen as a signal of bad corporate goverance. To measure what ‘too high’ means, we first need to establish a baseline of normal levels of compensation. 2. How should CEOs be incentivised: equity or options? How schould we measure whether CEOs have appropriate incentives: $ for $ increases, % for % increases? Incentives are a big topic in Accounting and Finance."
  },
  {
    "objectID": "slides/slides1.html#firm-production-function",
    "href": "slides/slides1.html#firm-production-function",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Firm production function",
    "text": "Firm production function\n\\[\nV = T^{\\alpha_T} \\Bigl( \\frac{K}{\\alpha_K} \\Bigl)^{\\alpha_K}\n                 \\Bigl( \\frac{L}{\\alpha_L} \\Bigl)^{\\alpha_L}\n\\]\n\\[\n\\alpha_T + \\alpha_K + \\alpha_L = 1\n\\]\n\n\\(V =\\) The value of the firm\n\\(K =\\) Capital of the firm\n\\(L =\\) Labour of the firm\n\\(T =\\) CEO talent/skills/ability/experience\n\n\nWe assume that there is nothing in the structure of the production function that favours a particular firm size, i.e. constant returns to scale."
  },
  {
    "objectID": "slides/slides1.html#ceo-decision",
    "href": "slides/slides1.html#ceo-decision",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "CEO decision",
    "text": "CEO decision\n\\[\n\\max_{K, L} W_T = V - w_L L - rK\n\\]\n\n\\(W_T =\\) wage for CEO with talent T\n\\(w_L =\\) labour unit costs\n\\(r =\\) cost of capital (or return on capital for investors)\n\n\nThe CEO maximises their income \\(W_T\\) by attracting capital at a cost, \\(r\\), and and hiring labour at a wage, \\(w_L\\). The model assumes that the CEO takes the ultimate decision. As it turns out when you assume competitive labour and financial markets, that assumptions does not really matter a lot.\nThis model is too simple to capture reality perfectly. However, that is not the goal of the model and of this exercise. The idea is to see whether we can find a reasonable baseline for CEO compensation that we can test against the data."
  },
  {
    "objectID": "slides/slides1.html#relation-between-size-and-ceo-wage",
    "href": "slides/slides1.html#relation-between-size-and-ceo-wage",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Relation between size and CEO wage",
    "text": "Relation between size and CEO wage\n\\[\nW_T = \\alpha_T V\n\\]\n\nIn this model, the driving force is that more talented CEOs grow the business to a bigger size and they earn more money when they create more value.\n\n\nFirst find the optimal level of capital …\n\\[\n\\begin{aligned}\n\\frac{\\partial W_T}{\\partial K} &=  T^{\\alpha_T}  \n\\Bigl( \\frac{K}{\\alpha_K} \\Bigl)^{\\alpha_K - 1}\n\\Bigl( \\frac{L}{\\alpha_L} \\Bigl)^{\\alpha_L} - r = 0\n\\\\\nT^{\\alpha_T} \\Bigl( \\frac{K}{\\alpha_K} \\Bigl)^{\\alpha_K}\n\\Bigl( \\frac{L}{\\alpha_L} \\Bigl)^{\\alpha_L}\n\\frac{\\alpha_K}{K}\n&= r\n\\\\\n\\frac{V}{r} &= \\frac{K}{\\alpha_K}\n\\end{aligned}\n\\]\n… and labour\n\\[\n\\begin{aligned}\n\\frac{\\partial W_T}{\\partial K} &=  T^{\\alpha_T}  \n\\Bigl( \\frac{K}{\\alpha_K} \\Bigl)^{\\alpha_K}\n\\Bigl( \\frac{L}{\\alpha_L} \\Bigl)^{\\alpha_L - 1} - w_L\n\\\\\nT^{\\alpha_T} \\Bigl( \\frac{K}{\\alpha_K} \\Bigl)^{\\alpha_K}\n\\Bigl( \\frac{L}{\\alpha_L} \\Bigl)^{\\alpha_L}\n\\frac{\\alpha_L}{L} &= w_L\n\\\\\n\\frac{V}{w_L} &= \\frac{L}{\\alpha_L}\n\\end{aligned}\n\\]\nNow we can plugin \\(L\\) and \\(K\\) in \\(V\\) …\n\\[\n\\begin{align}\nV = T^{\\alpha_T} \\Bigl( \\frac{V}{r} \\Bigl) ^{\\alpha_K}\n\\Bigl( \\frac{V}{w_L} \\Bigl) ^{\\alpha_L}\n\\\\\nV^{1 - \\alpha_K - \\alpha_L} = \\frac{T^{\\alpha_T}}\n{r^{\\alpha_K} w_L^{\\alpha_L}}\n\\\\\nV^{\\alpha_T} = \\frac{T^{\\alpha_T}}\n{r^{\\alpha_K} w_L^{\\alpha_L}}\n\\\\\nV = \\frac{T}\n{r^{\\frac{\\alpha_K}{\\alpha_T}} w_L^{\\frac{\\alpha_L}{\\alpha_T}}}\n\\end{align}\n\\]\n… and in \\(W_T\\).\n\\[\n\\begin{align}\nW_T = V - V \\alpha_K - V\\alpha_L = (1 - \\alpha_K - \\alpha_L) V\n= \\alpha_T V\n\\end{align}\n\\]\nI like the basic intuition and deriviation of the model. The derivation is straightforward and (some of) the implicit assumptions are relatively easy to accept. The effect of the CEO depends on the size of the firm (\\(V\\)). When there is more capital and labour available a more talented CEO will have a bigger impact. The model also predicts a clear quantitative relationship between firm size, \\(V\\), and CEO compensation, \\(W_T\\), i.e. that relationship should be linear. This is a nice result that we can test with data. In contrast to the linear relationship between firm size and CEO talent. We can measure \\(V\\) but not \\(T\\)."
  },
  {
    "objectID": "slides/slides1.html#data-compensation-value",
    "href": "slides/slides1.html#data-compensation-value",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Data: Compensation-Value",
    "text": "Data: Compensation-Value\n\n\n\n\n\nThe data is downloaded from Compustat and Execucomp. A lot of you will use these are similar databases in your research project. I did not clean or check the data for this exercise. In your own project, you should show a better understanding of how the data are gathered and what they include than what I am displaying here.\n\nCEO compensation is fairly complete. It includes changes in the value of equity and options.\nMarket value also includes all outstanding financial instruments on the company.\n\nThe qualitative relationship holds quite well. Bigger companies have CEOs with higher compensation. However, the relationship is far from linear and looks more like a power function. Clearly there are other effects at play. In this sample, the power coefficient is 0.31. Prior studies have found a coefficient more closely to 0.33 (Baker, Jensen, and Murphy 1988). Remember that in our setup the CEO can grow the firm at will by attracting more capital and more labour. That assumption is probably too strong."
  },
  {
    "objectID": "slides/slides1.html#the-research-process",
    "href": "slides/slides1.html#the-research-process",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "The research process",
    "text": "The research process\n\n\n\n\n\n\nSummary\n\n\n\nMake assumptions\nDerive relationship between measurable quantities\nCompare the theory and the data\n\n\n\n\n\n\nNote what we have just done. We started with some assumptions about the production function of a company and competitive markets to find the theoretical relation between firm size and CEO compensation. We followed up by testing this theory to data from S&P500 firms. These are the steps that you should be following."
  },
  {
    "objectID": "slides/slides1.html#literature-search",
    "href": "slides/slides1.html#literature-search",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Literature search",
    "text": "Literature search\n\nGoogle Scholar\nUWA One Search\nWeb of Knowledge\nEBSCOhost Research Databases\nSocial Science Research Network\nNational Bureau of Economic Research\n\n\nIn the CEO compensation case above, we derived the theoretical prediction. Normally, you will build on prior theoretical and empirical research to build predictions. The\nIn most cases (ssrn is the exception), you will have to be on the university’s network if you want to actually read the full paper.\n\nGoogle Scholar is probably the most comprehensive repository. This search engine work very similar to regular Google search. There are some additional tricks you can use “author:lastname-firstname” will help you to narrow down papers from a specific author. “intitle:keyword” let’s you search for keywords in the title of papers. You can also narrow down your search based on year of publication. The advanced search features hidden in the left side bar give you additional options such as searching for certain journals. If you are on the university network, Google Scholar will tell you for every paper\nOnesearch is the university search engine. It’s the best way to figure out whether there is an easily accessible version of the paper.\nWebofknowledge and EBSCOhost are two publisher driven initiatives. They work pretty well. Each with their own quirks.\nSSRN (Social Science Research Network) and NBER (National Bureau of Economic Research) both provide access to their own not-yet-peer-reviewed paper repositories. Here you go to find cutting edge research."
  },
  {
    "objectID": "slides/slides1.html#start-of-literature-search",
    "href": "slides/slides1.html#start-of-literature-search",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Start of literature search",
    "text": "Start of literature search\n\nDon’t start too narrow!\nReview articles and journals\n\nJournal of Economic Literature\nJournal of Accounting Literature\n\nA*/A journals\n\nAccounting\nFinance\n\n\n\nMy favourite way to start a research project now is to find one or two excellent overview or review papers. A (systematic) review paper provides a state of a research field and identifies interesting new research questions. I am not sure whether my strategy will work for you. I find that a good review paper gives a good list of papers you can build on and they often already compare the most important papers in a field. The trick is to be not too picky. You probably will not find a review for your exact reserch problem but it is unlikely that you will not find a partly relevant overview paper. You can search for review papers by adding “intitle:review” or “intitle:overview” to your Google Scholar search.\nTo find other papers relevant to your topic, you can build on the review paper by (1) looking up the papers referred to in the review paper and (2) search for papers that cite the review paper. You can do the latter via Google Scholar and Webofknowledge.\nTo find good reviews, I think you should start your search in the better journals. Some journals are dedicated to these literature reviews for instance Journal of Economic Literature and Journal of Accounting Literature. I am not aware of a similar journal in finance but I will happily add it if you let me know.\nWhen you start your literature search, you don’t want to narrow. You are not going to find an overview paper about “CEO compensation in Australian mining companies after the GFC”. However, you can start with an overview paper about CEO compensation. Like the one I found: “Executive Compensation: A Modern Primer” by Alex Edmans and Xavier Gabraix in Journal of Economic Literature."
  },
  {
    "objectID": "slides/slides1.html#signs-of-bad-workload-management",
    "href": "slides/slides1.html#signs-of-bad-workload-management",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Signs of bad workload management",
    "text": "Signs of bad workload management\n\nIrregular sleeping habits\nLoss of motivation\nPostponing difficult tasks"
  },
  {
    "objectID": "slides/slides1.html#working-with-a-supervisor",
    "href": "slides/slides1.html#working-with-a-supervisor",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Working with a supervisor",
    "text": "Working with a supervisor\n\nThe role of the supervisor\n\n\nGuide you towards a feasible research project\nHelp you finish the dissertation\n\n\nWork process\n\n\nSchedule weekly or fortnightly meetings\nSubmit writing or data analysis before every meeting.\n\n\nAdd a tl;dr section.\n\n\nYour supervisor is not your copy-editor, let them know when you submit an “early” draft.\nTell your supervisor what has changed\nClarify the sample and the main variables in tables\nTell your supervisor what the main table or figure is"
  },
  {
    "objectID": "slides/slides1.html#managing-the-workload-40-hours-per-week",
    "href": "slides/slides1.html#managing-the-workload-40-hours-per-week",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Managing the workload (40 hours per week)",
    "text": "Managing the workload (40 hours per week)\n\nPlan ahead (with your supervisor) towards major deadlines\nIt’s okay to submit partial assignments, as long as you make progress. (Especially for programming exercises)\nKeep writing!\nReach out when you need help with planning or when you feel overwhelmed.\n\nstijn.masschelein@uwa.edu.au\nUWA Counselling services\n\n\n\nThe plan can be an excel sheet with deadlines and milestones. Breaking down 5000 words into 10 weeks of 500 words is a lot less daunting."
  },
  {
    "objectID": "slides/slides1.html#questions",
    "href": "slides/slides1.html#questions",
    "title": "Introduction to Research Methods in Finance and Accounting",
    "section": "Questions",
    "text": "Questions\n\nAnswer in Quarto (.qmd) format. File > New File > Quarto Document ... >\nYou can use the code examples that I used in the video. I have uploaded the file to LMS. Use a different level 2 header for each question. Use R chunks to\n\nLoad the CEO compensation data from LMS so that you can work with it.\nPrint the dataset with only the CEOs without a cash bonus in 2013. You do not need to print the whole dataset. The default number of lines is sufficient.\nCalculate the number of observations, and the average and median bonus per year for the entire dataset.\n\nClick the Render button and upload the qmd and html version to LMS.\n\n\nThere is going to be some trial-and-error and debugging. That is fine. Carefully read the errors you get and use the resouces for help. Don’t be afraid to ask me or each other for help.\n\nGive a name to your document and enter your name\nSee the examples\nSee the render button in RStudio"
  },
  {
    "objectID": "slides/slides2.html#why-simulate-data",
    "href": "slides/slides2.html#why-simulate-data",
    "title": "Simulations, Regressions, and Significance",
    "section": "Why simulate data?",
    "text": "Why simulate data?\n\nVisualising your theory\nExperimenting with and understanding statistical tests\nExperimenting with statistical approaches without peaking at your data\n\nSee also Chapter 15 in Huntington-Klein (2021)\n\n\nVisualising can help you sharpen your intuition for your theory and for which values are reasonable and which are not.\nYou can simulate variables and causal structures that you cannot observe. See also this week’s homework\nYou don’t want to just decide on which statistical test to use because it gives you the “right” answer. If you want to experiment with different statistical models, you can do that with simulated data."
  },
  {
    "objectID": "slides/slides2.html#simulating-distributions-in-r",
    "href": "slides/slides2.html#simulating-distributions-in-r",
    "title": "Simulations, Regressions, and Significance",
    "section": "Simulating distributions in R",
    "text": "Simulating distributions in R\n\nN <- 1000\nrandom <- tibble(\n  normal = rnorm(N, 2, 5),\n  uniform = runif(N, 1, 5),\n  binomial = rbinom(N, 1, .25),\n  sample = sample(1:10, N, replace = T)\n)\nglimpse(random)\n\nRows: 1,000\nColumns: 4\n$ normal   <dbl> 10.9578770, -0.2808676, -0.0516203, 1.638…\n$ uniform  <dbl> 3.385180, 3.162932, 1.341290, 1.148682, 2…\n$ binomial <int> 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,…\n$ sample   <int> 3, 3, 6, 8, 10, 8, 4, 8, 2, 4, 2, 7, 9, 8…"
  },
  {
    "objectID": "slides/slides2.html#better-code-formatting",
    "href": "slides/slides2.html#better-code-formatting",
    "title": "Simulations, Regressions, and Significance",
    "section": "Better Code Formatting",
    "text": "Better Code Formatting\n\np1 <- ggplot(random, aes(x = normal)) +\n  geom_density() +\n  ggtitle(\"normal density\")\np2 <- ggplot(random, aes(x = uniform)) +\n  geom_histogram(bins = 50) +\n  ggtitle(\"uniform histogram\")\np3 <- ggplot(random, aes(x = binomial, y = normal)) +\n  geom_point() +\n  ggtitle(\"binomal-normal\")\np4 <- ggplot(random, aes(x = as.factor(sample), y = uniform)) +\n  geom_jitter(width = .2) +\n  ggtitle(\"sample-uniform\") + labs(x = \"sample\")\nplot_grid(p1, p2, p3, p4, ncol = 4)"
  },
  {
    "objectID": "slides/slides2.html#new-theory",
    "href": "slides/slides2.html#new-theory",
    "title": "Simulations, Regressions, and Significance",
    "section": "New theory",
    "text": "New theory\n\n\n\n\n\n\nSummary\n\n\n\nFirms have different size and CEOs have different talent.\nMore talented CEOs work for bigger firms.\nFirms pay just enough so that the CEO is not tempted to work for a smaller firm.\n\n\n\n\n\n\nThe model is the second one presented in Edmans and Gabaix (2016). A more rigorous proof is shown in Tervio (2008). A simplified explanation is in Chapter 5 of my lecture notes"
  },
  {
    "objectID": "slides/slides2.html#visualisation-of-matching-theory",
    "href": "slides/slides2.html#visualisation-of-matching-theory",
    "title": "Simulations, Regressions, and Significance",
    "section": "Visualisation of matching theory",
    "text": "Visualisation of matching theory\n\n\n\n\nCode\nobs <- 500\nsize_rate <- 1; talent_rate <- 2/3;\nC <- 1/60; w0 = 1;\nn <- c(1:obs)\nsize <-  600 * n ^ (-size_rate)\ntalent <- - 1/talent_rate * n ^ (talent_rate)\n\nwage <- rep(NA, obs)\nwage[obs] <- w0\nfor (i in (obs - 1):1){\n  wage[i] <- wage[i + 1] + C * size[i + 1] *\n      (talent[i] - talent[i + 1])\n}\n\nmatching_plot <- qplot(x = size, y = wage) +\n    labs(x = \"Company Market Value\", y = \"CEO compensation\")\nplot(matching_plot + ggtitle(\"Value - Compensation\"))\n\n\n\n\n\n\n\n\nCode\nplot(matching_plot +\n     scale_x_continuous(trans = \"log\",\n                        breaks = scales::log_breaks(n=5, base=10)) +\n     scale_y_continuous(trans = \"log\",\n                        breaks = scales::log_breaks(n=5, base=5)) +\n     ggtitle(\"log(Value) - log(Compensation)\")\n     )"
  },
  {
    "objectID": "slides/slides2.html#ceo-compensation-data",
    "href": "slides/slides2.html#ceo-compensation-data",
    "title": "Simulations, Regressions, and Significance",
    "section": "CEO compensation data",
    "text": "CEO compensation data\n\nus_comp <- readRDS(here(\"data\", \"us-compensation-new.RDS\")) %>%\n  rename(total_comp = tdc1)\nus_value <- readRDS(here(\"data\", \"us-value-new.RDS\")) %>%\n  rename(year = fyear, market_value = mkvalt)\nsummary(us_value$market_value)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n      0.0     925.7    2573.0   13586.4    8236.7 2324390.2 \n     NA's \n     4086"
  },
  {
    "objectID": "slides/slides2.html#putting-it-all-together-with-_join",
    "href": "slides/slides2.html#putting-it-all-together-with-_join",
    "title": "Simulations, Regressions, and Significance",
    "section": "Putting it all together with _join",
    "text": "Putting it all together with _join\n\nus_comp_value <-\n    select(us_comp, gvkey, year, total_comp) %>% \n    left_join(\n        us_value,\n        by = c(\"year\", \"gvkey\"))\nglimpse(us_comp_value)\n\nRows: 30,068\nColumns: 5\n$ gvkey        <chr> \"001004\", \"001004\", \"001004\", \"001004…\n$ year         <dbl> 2011, 2011, 2012, 2013, 2014, 2015, 2…\n$ total_comp   <dbl> 5786.400, 5786.400, 4182.832, 5247.77…\n$ market_value <dbl> 485.2897, 485.2897, 790.0029, 961.308…\n$ ni           <dbl> 67.723, NA, 55.000, 72.900, 10.200, 4…\n\n\n\n\nMore information on joins to merge two datasets on the tidyverse website. I prefer the left_join function as the default because it indicates that we have a main dataset (left) to which we want to add a second dataset (right). We will also spend more time with these functions in week 7."
  },
  {
    "objectID": "slides/slides2.html#first-plot",
    "href": "slides/slides2.html#first-plot",
    "title": "Simulations, Regressions, and Significance",
    "section": "First plot",
    "text": "First plot\n\nThe BasicsThe scalesZoom in\n\n\n\n\n\nplot_comp_value <- ggplot(\n    us_comp_value,\n    aes(y = total_comp, x = market_value)) +\n    geom_point(alpha = .10) +\n    ylab(\"compensation ($ 000)\") +\n    xlab(\"market value ($ million)\")\n\n\n\nprint(plot_comp_value)\n\n\n\n\n\n\n\n\n\n\n\nplot_log <- plot_comp_value +\n    scale_x_continuous(\n        trans = \"log1p\",\n        breaks = c(1e2, 1e3, 1e4, 1e5, 1e6),\n        labels = function(x)\n            prettyNum(x/1000, digits = 2)) +\n    scale_y_continuous(\n        trans = \"log1p\",\n        breaks = c(1e1, 1e2, 1e3, 1e4, 1e5),\n        labels = function(x)\n            prettyNum(x/1000, digits = 2)) +\n    ylab(\"compensation ($ million)\") +\n    xlab(\"market value ($ billion)\")\n\n\n\nprint(plot_log)\n\n\n\n\n\n\n\n\n\n\n\nplot_zoom <- plot_log +\n    coord_cartesian(\n        xlim = c(1e1, NA), ylim = c(1e2, NA))\n\n\n\nprint(plot_zoom)"
  },
  {
    "objectID": "slides/slides2.html#notation",
    "href": "slides/slides2.html#notation",
    "title": "Simulations, Regressions, and Significance",
    "section": "Notation",
    "text": "Notation\n\n\n\\[\\begin{equation}\ny_i = a + b_1 x_{1i} + ... + b_n x_{ni} + \\epsilon_i\n\\end{equation}\\]\n\\[\\begin{equation}\n\\vec{y} = a + b_1 \\vec{x_1} + ... b_n \\vec{x_n} + \\vec{\\epsilon}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\vec{y} = a + \\vec{b} X + \\vec{\\epsilon}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\vec{y} = \\mathcal{N}(a + \\vec{b} X, \\sigma)\n\\end{equation}\\]\nSee also Chapter 13 in Huntington-Klein (2021)\n\n\nreg <- lm(y ~ x1 + x2, data = my_data_set)\nsummary(reg)"
  },
  {
    "objectID": "slides/slides2.html#finally-the-regression",
    "href": "slides/slides2.html#finally-the-regression",
    "title": "Simulations, Regressions, and Significance",
    "section": "Finally, the regression",
    "text": "Finally, the regression\n\nreg <- lm(log(total_comp + 1) ~ log(market_value + 1),\n         data = us_comp_value)\n# summary(reg)\nprint(summary(reg)$coefficients, digits = 2)\n\n                      Estimate Std. Error t value Pr(>|t|)\n(Intercept)                5.2     0.0263     197        0\nlog(market_value + 1)      0.4     0.0032     122        0\n\n\n\n\nThe regression uses a trick with the log(... + 1) formulation which is probably not appropriate. We will see the poisson regression later for a more appropriate way of analysing the effect on a positive variable."
  },
  {
    "objectID": "slides/slides2.html#historical-discussion",
    "href": "slides/slides2.html#historical-discussion",
    "title": "Simulations, Regressions, and Significance",
    "section": "Historical Discussion",
    "text": "Historical Discussion\n\nOur estimates of the pay-performance relation (including pay, options, stockholdings, and dismissal) for chief executive officers indicate that CEO wealth changes $3.25 for every $1,000 change in shareholder wealth (Jensen and Murphy 1990).\n\n\n\n[…] The statistic in isolation can present a misleading picture of pay to performance relationships because the denominator - the change in firm value - is so large (Hall and Liebman 1998).\n\n\n\n\nThis article addresses four major concerns about the pay of U.S. CEOs: (1) failure to pay for performance; […]. The authors’ main message is that most if not all of these concerns are exaggerated by the popular tendency to focus on the annual income of CEOs (consisting of salary, bonus, and stock and option grants) while ignoring their existing holdings of company equity (Core, Guay, and Thomas 2005).\n\n\nThis is actually a good example of why a literature review is valuable. It’s not enough to just say that the three papers find different effects. They do more than that. The newer papers gradually build up a better theory of what happens in practice and use better measures to reflect that theory."
  },
  {
    "objectID": "slides/slides2.html#stock-holding-data",
    "href": "slides/slides2.html#stock-holding-data",
    "title": "Simulations, Regressions, and Significance",
    "section": "Stock holding data",
    "text": "Stock holding data\n\nus_comp <- readRDS(here(\"data\", \"us-compensation-new.RDS\")) %>%\n    rename(total_comp = tdc1, shares = shrown_tot_pct) %>%\n    select(gvkey, execid, year, shares, total_comp)\nus_value <- readRDS(here(\"data\", \"us-value-new.RDS\")) %>%\n    rename(year = fyear, market_value = mkvalt) %>%\n    select(-ni) \nus_comp_value <- left_join(\n    us_comp, us_value, by = c(\"year\", \"gvkey\")) %>%\n    filter(!is.na(market_value) & !(is.na(shares))) %>%\n    mutate(wealth = shares * market_value / 100)\nglimpse(us_comp_value)\n\nRows: 25,707\nColumns: 7\n$ gvkey        <chr> \"001004\", \"001004\", \"001004\", \"001004…\n$ execid       <chr> \"09249\", \"09249\", \"09249\", \"09249\", \"…\n$ year         <dbl> 2011, 2011, 2012, 2013, 2014, 2015, 2…\n$ shares       <dbl> 2.964, 2.964, 2.893, 3.444, 3.877, 4.…\n$ total_comp   <dbl> 5786.400, 5786.400, 4182.832, 5247.77…\n$ market_value <dbl> 485.2897, 485.2897, 790.0029, 961.308…\n$ wealth       <dbl> 14.383987, 14.383987, 22.854784, 33.1…"
  },
  {
    "objectID": "slides/slides2.html#shares-to-market-value",
    "href": "slides/slides2.html#shares-to-market-value",
    "title": "Simulations, Regressions, and Significance",
    "section": "Shares to Market Value",
    "text": "Shares to Market Value\n\n\n\nplot_shares <- ggplot(\n    data = us_comp_value,\n    aes(x = market_value/1000, y = shares)) +\n    geom_point(alpha = .10) +\n    ylab(\"CEO Ownership\") +\n    xlab(\"Firm Market Value (in Billions)\") +\n    scale_x_continuous(\n        trans = \"log\",\n        labels = function(x)\n            prettyNum(x, digits = 2),\n        breaks =\n            scales::log_breaks(n = 5,\n                               base = 10)) +\n    scale_y_continuous(\n        trans = \"log\",\n        labels =\n            function(x)\n                prettyNum(x, digits = 2),\n        breaks =\n            scales::log_breaks(n = 5,\n                               base = 10))\n\n\n\nprint(plot_shares)"
  },
  {
    "objectID": "slides/slides2.html#pay-to-performance-sensitivity",
    "href": "slides/slides2.html#pay-to-performance-sensitivity",
    "title": "Simulations, Regressions, and Significance",
    "section": "Pay to Performance Sensitivity",
    "text": "Pay to Performance Sensitivity\n\nDataPlot\n\n\n\nus_sens <- us_comp_value %>%\n    group_by(gvkey, execid) %>%\n    arrange(year) %>%\n    mutate(prev_market_value = lag(market_value),\n            prev_wealth = lag(wealth)) %>%\n    ungroup() %>%\n    mutate(change_log_value = log(market_value) - log(prev_market_value),\n           change_log_wealth = log(wealth) - log(prev_wealth)) %>%\n    filter(!is.infinite(change_log_wealth)) %>%\n    arrange(gvkey)\n\n\n\nThe assumption for pay-for-performance and incentives is that we want to measure whether a CEO has taken the correct decisions. In a bigger firm, the impact of a CEOs decisions are larger. If you improve management of employees, then the effects will be bigger for a firm with more employees.\nThe other assumption is that CEOs do not care about dollar increases in dollars but in increases in percentages. Partly\n\n\\[\n\\begin{align}\n\\frac{\\partial W}{W} \\frac{V}{\\partial V}  \\\\\n  &= \\frac{ln(W)}{ln(V)}\n\\end{align}\n\\]\n\n\n\n\n\n\nplot_hypothesis <- ggplot(\n    us_sens,\n    aes(y = change_log_wealth / change_log_value,\n        x = market_value/1000)) +\n  geom_point(alpha = .1) +\n  scale_x_continuous(\n    trans = \"log\", \n    breaks = scales::log_breaks(n = 5, base = 10),\n    labels = function(x) prettyNum(x, dig = 2)) +\n  coord_cartesian(\n    ylim = c(-10, 10)) +\n  xlab(\"market value\") +\n  ylab(\"sensitivity\")\n\n\n\nprint(plot_hypothesis)"
  },
  {
    "objectID": "slides/slides2.html#randomisation-or-permutation-test",
    "href": "slides/slides2.html#randomisation-or-permutation-test",
    "title": "Simulations, Regressions, and Significance",
    "section": "Randomisation or Permutation Test",
    "text": "Randomisation or Permutation Test\n\nRandomisationTest\n\n\n\ndata_hypo <- us_sens %>%\n    mutate(\n      sensitivity = change_log_wealth / change_log_value) %>%\n  select(sensitivity, market_value) %>%\n  filter(complete.cases(.))\n\nobserved_cor <- cor(\n  data_hypo$sensitivity, data_hypo$market_value)\n\nrandom_cor <- cor(\n  data_hypo$sensitivity, sample(data_hypo$market_value))\n\nprint(prettyNum(c(observed_cor, random_cor), dig = 3))\n\n[1] \"-0.00322\" \"0.000549\"\n\n\n\n\n\n\n\nsimulate_cor <- function(data){\n    return(cor(data$sensitivity,\n               sample(data$market_value)))}\nrand_cor <- replicate(1e4,\n                      simulate_cor(data_hypo))\n\n\nhist_sim <- ggplot(\n    mapping = aes(\n        x = rand_cor,\n        fill = abs(rand_cor) < abs(observed_cor))) +\n    geom_histogram(bins = 1000) +\n    xlab(\"Random Correlations\") +\n    scale_fill_manual(values = c(uwa_blue, uwa_gold)) +\n    theme(legend.position = \"none\") +\n    coord_cartesian(\n        xlim = c(-0.1, 0.1))\n\n\n\nplot(hist_sim)"
  },
  {
    "objectID": "slides/slides2.html#bootstrap",
    "href": "slides/slides2.html#bootstrap",
    "title": "Simulations, Regressions, and Significance",
    "section": "Bootstrap",
    "text": "Bootstrap\n\n\n\ncalc_corr <- function(d){\n  n <- nrow(d)\n  id_sample <- sample(1:n, size = n,\n                      replace = TRUE)\n  sample <- d[id_sample, ]\n  corr <- cor(sample$sensitivity,\n              sample$market_value)\n  return(corr)\n}\nboot_corr <- replicate(\n    2000, calc_corr(data_hypo))\n\n\nplot_boot <- ggplot(\n    mapping = aes(x = boot_corr)) +\n  geom_histogram(bins = 100, colour = uwa_blue,\n                 fill = uwa_blue) +\n    geom_vline(aes(xintercept = 0),\n               colour = uwa_gold) +\n    xlab(\"Bootstrapped Correlation\")\n\n\n\nprint(plot_boot)"
  },
  {
    "objectID": "slides/slides2.html#comparison",
    "href": "slides/slides2.html#comparison",
    "title": "Simulations, Regressions, and Significance",
    "section": "Comparison",
    "text": "Comparison\n\n\nPermutation Test\n\nCalculate the observed statistic\nRandomly resample the data by breaking the relation you want to test (= Null Hypothesis)\nCalculate the statistic for each random sample\nIs the observed statistic more extreme than the randomly resampled statistic?\n\nSee also Chapter 4.2 in Cunningham (2021)\n\nBootstrap\n\nRandomly sample observed observations with replacement.\nCalculate the statistic you are interested in.\nIs the distribution of resampled statistics unlikely to be 0 (= Null Hypothesis)?\n\nSee also Chapter 15 in Huntington-Klein (2021)"
  },
  {
    "objectID": "slides/slides2.html#formula-based-p-value",
    "href": "slides/slides2.html#formula-based-p-value",
    "title": "Simulations, Regressions, and Significance",
    "section": "Formula Based P-value",
    "text": "Formula Based P-value\n\ncor <- cor.test(data_hypo$sensitivity, data_hypo$market_value)\npvalue_cor <- cor$p.value\nprint(prettyNum(pvalue_cor, dig = 2))\n\n[1] \"0.69\"\n\n\n\n\nregr_sens <- lm(sensitivity ~ I(market_value/1e3), data = data_hypo)\ncoefficients(summary(regr_sens)) %>% print(dig = 2)\n\n                     Estimate Std. Error t value Pr(>|t|)\n(Intercept)            1.4973      1.070    1.40     0.16\nI(market_value/1000)  -0.0062      0.016   -0.39     0.69"
  },
  {
    "objectID": "slides/slides2.html#models",
    "href": "slides/slides2.html#models",
    "title": "Simulations, Regressions, and Significance",
    "section": "Models",
    "text": "Models\n\n\nSignaling Model\n\n\n\nPeacock’s tail as a signal\n\n\n\nCheap Talk Model\n\n\n\nAssumptions are important"
  },
  {
    "objectID": "slides/slides2.html#answers",
    "href": "slides/slides2.html#answers",
    "title": "Simulations, Regressions, and Significance",
    "section": "Answers",
    "text": "Answers\n\nN <- 1000\nhigh_performance <- rbinom(.x, .y, .z)\ndonation <- ifelse(.x, 1, 0)\nreturn <- ifelse(donation == 1, .y, .z)\nobserved_donation <- ifelse(rbinom(N, 1, .9) == 1, donation, 1 - donation)\nobserved_return <- ... \nsig <- tibble(return = ...,\n              donation = ...) %>%\n    mutate(donated = ...)\nglimpse(sig)\n\n\n\nsig_plot <- ggplot(..., aes(x = .x, y = .y)) +\n    geom_jitter(width = .3)\nplot(sig_plot)\n\n\n\n\nsig_reg <- lm(..., data = sig)\nsummary(...)"
  },
  {
    "objectID": "slides/slides3.html#an-example-of-a-causal-graph",
    "href": "slides/slides3.html#an-example-of-a-causal-graph",
    "title": "Control Variables",
    "section": "An Example of a Causal Graph",
    "text": "An Example of a Causal Graph\n\n\n\n\n\n\n\nbrand_capital\n\n  \n\nInfoEnvironment\n\n InfoEnvironment   \n\nCreditRating\n\n CreditRating   \n\nInfoEnvironment->CreditRating\n\n    \n\nFutureCashFlow\n\n FutureCashFlow   \n\nFutureCashFlow->CreditRating\n\n    \n\nBrandCapital\n\n BrandCapital   \n\nBrandCapital->InfoEnvironment\n\n    \n\nBrandCapital->FutureCashFlow"
  },
  {
    "objectID": "slides/slides3.html#difference-with-equilibrium-models",
    "href": "slides/slides3.html#difference-with-equilibrium-models",
    "title": "Control Variables",
    "section": "Difference with equilibrium models",
    "text": "Difference with equilibrium models\n\n\n\n\n\n\nDifferences\n\n\n\nAll the qualitative information about causal relations is in the graph.\nThe equilibrium model directly gives the relation between the variables of interest.\n\ne.g.: Signaling model\n\n\n\n\n\n\n\n\n\n\ndonations\n\n  \n\nPerformance\n\n Performance   \n\nDonation\n\n Donation   \n\nPerformance->Donation\n\n    \n\nReturn\n\n Return   \n\nDonation->Return\n\n   \n\n\n\n\n\n\n\nIs there a relation between Performance and Return?\nThere is a parallel with voluntary disclosure of information that the company does not have.\nWhat happens if firms are no longer allowed to donate? What happens if firms are all forced to donate?"
  },
  {
    "objectID": "slides/slides3.html#assignment-csr-report",
    "href": "slides/slides3.html#assignment-csr-report",
    "title": "Control Variables",
    "section": "Assignment: CSR report",
    "text": "Assignment: CSR report\n\n\n\n\n\n\n\nmeasurement_error\n\n  \n\nPerformance\n\n Performance   \n\nCSR_report\n\n CSR_report   \n\nPerformance->CSR_report\n\n    \n\nScandals\n\n Scandals   \n\nPerformance->Scandals\n\n    \n\nReturn\n\n Return   \n\nCSR_report->Return\n\n    \n\nObserved_Report\n\n Observed_Report   \n\nCSR_report->Observed_Report\n\n   \n\n\n\n\n\n\n\nWhat is the effect of an increase in scandals?\nWhat happens if we keep the number of scandals constant?"
  },
  {
    "objectID": "slides/slides3.html#causal-graph",
    "href": "slides/slides3.html#causal-graph",
    "title": "Control Variables",
    "section": "Causal Graph",
    "text": "Causal Graph\n\n\n\n\n\n\n\nmeasurement_error\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nTechIndustry\n\n TechIndustry   \n\nTechIndustry->Performance\n\n   \n\n\n\n\n\n\nAssume that we are interested in the role of the GC on performance."
  },
  {
    "objectID": "slides/slides3.html#simulation",
    "href": "slides/slides3.html#simulation",
    "title": "Control Variables",
    "section": "Simulation",
    "text": "Simulation\n\n\n\nset.seed(230383)\nN <- 1000\nds <- tibble(CG = runif(N, 0, 10),\n             TI = rbinom(N, 1, .25)) %>%\n  mutate(Performance =\n           rnorm(N, CG * .15 + TI * 10, 5))\n\n\nlm1 <- lm(Performance ~ CG, data = ds)\nlm2 <- lm(Performance ~ CG + TI, data = ds)\n\n\n\ngof_omit <- \"Adj|IC|Log|Pseudo\"\nstars <- c('*' = .1, '**' = .05, '***' = .01)\nmsummary(list(lm1, lm2), stars = stars,\n         gof_omit = gof_omit, output = \"html\")\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    2.976*** \n    0.036 \n  \n  \n     \n    (0.408) \n    (0.310) \n  \n  \n    CG \n    0.081 \n    0.130** \n  \n  \n     \n    (0.073) \n    (0.052) \n  \n  \n    TI \n     \n    10.433*** \n  \n  \n     \n     \n    (0.344) \n  \n  \n    Num.Obs. \n    1000 \n    1000 \n  \n  \n    R2 \n    0.001 \n    0.480 \n  \n  \n    F \n    1.233 \n    459.735 \n  \n  \n    RMSE \n    6.60 \n    4.76 \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\n\n\nMeasurement error typically decreases the effect and this is also what happened in the assignment. For instance, the difference between the donation and no donation should be 3 but it is less."
  },
  {
    "objectID": "slides/slides3.html#causal-graph-1",
    "href": "slides/slides3.html#causal-graph-1",
    "title": "Control Variables",
    "section": "Causal Graph",
    "text": "Causal Graph\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nTechIndustry\n\n TechIndustry   \n\nTechIndustry->CorporateGovernance\n\n    \n\nTechIndustry->Performance\n\n   \n\n\n\n\n\n\nThere is only 1 difference between this causal graph and the previous one."
  },
  {
    "objectID": "slides/slides3.html#simulation-1",
    "href": "slides/slides3.html#simulation-1",
    "title": "Control Variables",
    "section": "Simulation",
    "text": "Simulation\n\n\n\nN <- 1000\nds <- tibble(TI = rbinom(N, 1, .25)) %>%\n  mutate(CG = rnorm(N, .5 - TI, .2),\n         Performance = rnorm(N, TI + 0 * CG, 1))\n\n\nlm1 <- lm(Performance ~ CG, data = ds)\nlm2 <- lm(Performance ~ CG + TI, data = ds)\n\n\n\nmsummary(list(lm1, lm2), stars = stars,\n         gof_omit = gof_omit, output = \"html\")\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    0.473*** \n    0.002 \n  \n  \n     \n    (0.036) \n    (0.087) \n  \n  \n    CG \n    −0.945*** \n    −0.090 \n  \n  \n     \n    (0.067) \n    (0.159) \n  \n  \n    TI \n     \n    1.018*** \n  \n  \n     \n     \n    (0.172) \n  \n  \n    Num.Obs. \n    1000 \n    1000 \n  \n  \n    R2 \n    0.165 \n    0.193 \n  \n  \n    F \n    196.742 \n    119.276 \n  \n  \n    RMSE \n    1.01 \n    0.99 \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\n\n\nIn the simulation, we set the effect of GC equal to 0 i.e. there is not effect. The reason to do that is to show why it’s necessary to adjust for TI."
  },
  {
    "objectID": "slides/slides3.html#fixed-effects-as-a-special-case",
    "href": "slides/slides3.html#fixed-effects-as-a-special-case",
    "title": "Control Variables",
    "section": "Fixed effects as a special case",
    "text": "Fixed effects as a special case\n\n\n\n\n\n\nDefinition\n\n\nEffects that are the same for every industry, year, firm, or individual can be adjusted for by using fixed effects.\n\n\n\n\n\n\n\n\n\nBenefits\n\n\nWe do not need to measure the specific variables and can just use indicators variables for each category (e.g. for each different industry).\n\n\n\nSee more in chapter 16 of Huntington-Klein (2021)"
  },
  {
    "objectID": "slides/slides3.html#fixed-effects-for-industry",
    "href": "slides/slides3.html#fixed-effects-for-industry",
    "title": "Control Variables",
    "section": "Fixed effects (for industry)",
    "text": "Fixed effects (for industry)\n\nCausal DiagramSimulationRegressionsSimulation with correlated fixed effectsRegressions with correlated fixed effects\n\n\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nIndustry\n\n Industry   \n\nIndustry->CorporateGovernance\n\n    \n\nIndustry->Performance\n\n   \n\n\n\n\n\n\n\n\nNind <- 20\nN <- 5000\ndi <- tibble(\n  ind_number = 1:Nind,\n  ind_CG = rnorm(Nind, 0, 1),\n  ind_performance = rnorm(Nind, 0, 1)\n)\nds <- tibble(\n    ind_number = sample(1:Nind, N, replace = TRUE)) %>%\n  left_join(\n    di, by = \"ind_number\") %>%\n  mutate(\n    CG = rnorm(N, .5 + ind_CG, .2),\n    Performance = rnorm(N, 0 * CG + ind_performance, 1)\n  )\n\n\n\n\nglimpse(di, width = 50)\n\nRows: 20\nColumns: 3\n$ ind_number      <int> 1, 2, 3, 4, 5, 6, 7, 8, …\n$ ind_CG          <dbl> 0.23567083, -0.34180999,…\n$ ind_performance <dbl> 1.1335103, 1.2873377, 0.…\n\n\n\n\nglimpse(ds, width = 50)\n\nRows: 5,000\nColumns: 5\n$ ind_number      <int> 9, 12, 5, 7, 6, 8, 15, 1…\n$ ind_CG          <dbl> 1.91243572, 0.16031769, …\n$ ind_performance <dbl> 0.1773941, -0.1250858, 0…\n$ CG              <dbl> 2.3076069, 0.6604549, 1.…\n$ Performance     <dbl> 0.09219279, -0.37244401,…\n\n\n\n\n\n\n\nlm1 <- lm(Performance ~ CG, data = ds)\nlm2 <- lm(Performance ~ CG + factor(ind_number), data = ds)\nlibrary(fixest)\nfe <- feols(Performance ~ CG | ind_number, data = ds)\n\n\nmsummary(list(lm1, lm2, fe), gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n     (1) \n      (2) \n      (3) \n  \n \n\n  \n    (Intercept) \n    0.490*** \n    1.054*** \n     \n  \n  \n     \n    (0.019) \n    (0.080) \n     \n  \n  \n    CG \n    −0.076*** \n    0.030 \n    0.030 \n  \n  \n     \n    (0.018) \n    (0.071) \n    (0.061) \n  \n  \n    factor(ind_number)2 \n     \n    0.207** \n     \n  \n  \n     \n     \n    (0.097) \n     \n  \n  \n    factor(ind_number)3 \n     \n    −0.490*** \n     \n  \n  \n     \n     \n    (0.090) \n     \n  \n  \n    factor(ind_number)4 \n     \n    −0.372** \n     \n  \n  \n     \n     \n    (0.161) \n     \n  \n  \n    factor(ind_number)5 \n     \n    −0.410*** \n     \n  \n  \n     \n     \n    (0.099) \n     \n  \n  \n    factor(ind_number)6 \n     \n    −1.907*** \n     \n  \n  \n     \n     \n    (0.169) \n     \n  \n  \n    factor(ind_number)7 \n     \n    −0.083 \n     \n  \n  \n     \n     \n    (0.134) \n     \n  \n  \n    factor(ind_number)8 \n     \n    −1.191*** \n     \n  \n  \n     \n     \n    (0.178) \n     \n  \n  \n    factor(ind_number)9 \n     \n    −0.935*** \n     \n  \n  \n     \n     \n    (0.148) \n     \n  \n  \n    factor(ind_number)10 \n     \n    −1.712*** \n     \n  \n  \n     \n     \n    (0.087) \n     \n  \n  \n    factor(ind_number)11 \n     \n    −1.162*** \n     \n  \n  \n     \n     \n    (0.122) \n     \n  \n  \n    factor(ind_number)12 \n     \n    −1.118*** \n     \n  \n  \n     \n     \n    (0.090) \n     \n  \n  \n    factor(ind_number)13 \n     \n    0.765*** \n     \n  \n  \n     \n     \n    (0.091) \n     \n  \n  \n    factor(ind_number)14 \n     \n    −0.564*** \n     \n  \n  \n     \n     \n    (0.104) \n     \n  \n  \n    factor(ind_number)15 \n     \n    0.730*** \n     \n  \n  \n     \n     \n    (0.129) \n     \n  \n  \n    factor(ind_number)16 \n     \n    0.689*** \n     \n  \n  \n     \n     \n    (0.158) \n     \n  \n  \n    factor(ind_number)17 \n     \n    −2.056*** \n     \n  \n  \n     \n     \n    (0.098) \n     \n  \n  \n    factor(ind_number)18 \n     \n    −0.503*** \n     \n  \n  \n     \n     \n    (0.091) \n     \n  \n  \n    factor(ind_number)19 \n     \n    −1.907*** \n     \n  \n  \n     \n     \n    (0.093) \n     \n  \n  \n    factor(ind_number)20 \n     \n    0.608*** \n     \n  \n  \n     \n     \n    (0.086) \n     \n  \n  \n    Num.Obs. \n    5000 \n    5000 \n    5000 \n  \n  \n    R2 \n    0.003 \n    0.443 \n    0.443 \n  \n  \n    R2 Within \n     \n     \n    0.000 \n  \n  \n    F \n    17.363 \n    198.205 \n     \n  \n  \n    RMSE \n    1.34 \n    1.00 \n    1.00 \n  \n  \n    Std.Errors \n     \n     \n    by: ind_number \n  \n  \n    FE: ind_number \n     \n     \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\n\nWhy do we need the factor(ind_number) formulation?\n\n\n\n\n\nNind <- 20\nN <- 5000\ncorrel <- -0.5\ndi <- tibble(\n    ind_number = 1:Nind,\n    ind_CG = rnorm(Nind, 0, 1)) %>%\n  mutate(\n    ind_performance = sqrt(1 - correl^2) * rnorm(Nind, 0, 1) + correl * ind_CG)\nds <- tibble(\n    ind_number = sample(1:Nind, N, replace = TRUE)) %>%\n  left_join(\n    di, by = \"ind_number\") %>%\n  mutate(\n    CG = rnorm(N, .5 + ind_CG, .2),\n    Performance = rnorm(N, 0 * CG + ind_performance, 1)\n  )\n\n\n\n\nglimpse(di, width = 50)\n\nRows: 20\nColumns: 3\n$ ind_number      <int> 1, 2, 3, 4, 5, 6, 7, 8, …\n$ ind_CG          <dbl> -0.82999044, 0.44908313,…\n$ ind_performance <dbl> -1.12284290, -0.57326559…\n\n\n\n\nglimpse(ds, width = 50)\n\nRows: 5,000\nColumns: 5\n$ ind_number      <int> 20, 17, 2, 1, 9, 20, 5, …\n$ ind_CG          <dbl> -1.1358960, 0.4833522, 0…\n$ ind_performance <dbl> 1.0252155, -0.6131181, -…\n$ CG              <dbl> -0.79273388, 1.44367931,…\n$ Performance     <dbl> 1.75927497, -1.39745179,…\n\n\n\n\n\n\n\nlm1 <- lm(Performance ~ CG, data = ds)\nfe <- feols(Performance ~ CG | ind_number, data = ds)\n\n\nmsummary(list(lm1, fe), gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    −0.033 \n     \n  \n  \n     \n    (0.022) \n     \n  \n  \n    CG \n    −0.279*** \n    −0.012 \n  \n  \n     \n    (0.015) \n    (0.046) \n  \n  \n    Num.Obs. \n    5000 \n    5000 \n  \n  \n    R2 \n    0.067 \n    0.321 \n  \n  \n    R2 Within \n     \n    0.000 \n  \n  \n    F \n    360.997 \n     \n  \n  \n    RMSE \n    1.17 \n    1.00 \n  \n  \n    Std.Errors \n     \n    by: ind_number \n  \n  \n    FE: ind_number \n     \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\n\nWhy do we need the factor(ind_number) formulation?\nThe trick with the correlated ind_CG and ind_performance"
  },
  {
    "objectID": "slides/slides3.html#what-do-fixed-effects-do",
    "href": "slides/slides3.html#what-do-fixed-effects-do",
    "title": "Control Variables",
    "section": "What do fixed effects do?",
    "text": "What do fixed effects do?\n\nFull SampleHighlight IndustryRemove Industry Effects\n\n\n\n\nCode\nfe_plot <-\n  ggplot(ds, aes(y = Performance, x = CG)) +\n  geom_point()\nplot(fe_plot)\n\n\n\n\n\n\n\n\n\nCode\nfe_colour <-\n  ggplot(ds, aes(y = Performance, x = CG,\n                colour = factor(ind_number))) +\n  geom_point() + theme(legend.position=\"none\") \nplot(fe_colour)\n\n\n\n\n\n\n\n\n\nCode\nfe_demean <- group_by(ds, ind_number) %>%\n  mutate(Performance2 = Performance - mean(Performance),\n         CG2 = CG - mean(CG)) %>%\n  ggplot(aes(y = Performance2, x = CG2,\n             colour = factor(ind_number))) +\n  geom_point() + theme(legend.position=\"none\") \nplot(fe_demean)"
  },
  {
    "objectID": "slides/slides3.html#speedboat-racing-example-booth2017",
    "href": "slides/slides3.html#speedboat-racing-example-booth2017",
    "title": "Control Variables",
    "section": "Speedboat Racing Example (Booth and Yamamura 2017)",
    "text": "Speedboat Racing Example (Booth and Yamamura 2017)\n\n\n\nMixed-sex and single-sex races determined by lottery (Randomisation)\n7 race courses\nMultiple races in the same month and location\n\n\n\n\n\n\n\n\n\nspeedboat\n\n  \n\nave_ability\n\n ave_ability   \n\nltime\n\n ltime   \n\nave_ability->ltime\n\n    \n\nmixed_race\n\n mixed_race   \n\nmixed_race->ltime\n\n    \n\nfemale\n\n female   \n\nfemale->ave_ability\n\n    \n\nfemale->ltime\n\n    \n\ncourse\n\n course   \n\ncircumstances\n\n circumstances   \n\ncourse->circumstances\n\n    \n\nmonth_location\n\n month_location   \n\nmonth_location->circumstances\n\n    \n\ncircumstances->ltime\n\n    \n\ncircumstances->female"
  },
  {
    "objectID": "slides/slides3.html#results-of-speedboat-races",
    "href": "slides/slides3.html#results-of-speedboat-races",
    "title": "Control Variables",
    "section": "Results of Speedboat Races",
    "text": "Results of Speedboat Races\n\n\nCode\nload(here(\"data\", \"booth_yamamura.Rdata\"))\ntable <- as_tibble(table) %>%\n  select(p_id, women_dat, time, ltime, mix_ra, course,\n         race_id, yrmt_locid)\ntable_clean <- filter(table, complete.cases(table)) %>%\n  select(ltime, women_dat, mix_ra, course, p_id, race_id,\n         yrmt_locid)\nltime_reg <- feols(ltime ~ women_dat : mix_ra + mix_ra\n                   | course + p_id + yrmt_locid,\n                   cluster = \"race_id\",\n                   data = table_clean)\nmsummary(ltime_reg, gof_omit = gof_omit, stars = stars)\n\n\n\n\n \n  \n      \n     (1) \n  \n \n\n  \n    mix_ra \n    −0.002*** \n  \n  \n     \n    (0.000) \n  \n  \n    women_dat × mix_ra \n    0.007*** \n  \n  \n     \n    (0.001) \n  \n  \n    Num.Obs. \n    142346 \n  \n  \n    R2 \n    0.361 \n  \n  \n    R2 Within \n    0.001 \n  \n  \n    RMSE \n    0.02 \n  \n  \n    Std.Errors \n    by: race_id \n  \n  \n    FE: course \n    X \n  \n  \n    FE: p_id \n    X \n  \n  \n    FE: yrmt_locid \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\nThis requires an explanation of interactions. Luckily, it’s relatively simple with two discrete variables.\n| ltime | man    | woman  |\n|-------|:------:|:------:|\n| same  | 0      | 0      |\n| mixed | -0.002 | 0.005  |"
  },
  {
    "objectID": "slides/slides3.html#bad-controls-survival-bias-selection-bias-self-selection-bias",
    "href": "slides/slides3.html#bad-controls-survival-bias-selection-bias-self-selection-bias",
    "title": "Control Variables",
    "section": "Bad Controls, Survival Bias, Selection Bias, Self-Selection Bias",
    "text": "Bad Controls, Survival Bias, Selection Bias, Self-Selection Bias\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nStockPrice\n\n StockPrice   \n\nPerformance->StockPrice\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nSurvival\n\n Survival   \n\nPerformance->Survival\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nSP500\n\n SP500   \n\nPerformance->SP500\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nIPO\n\n IPO   \n\nPerformance->IPO"
  },
  {
    "objectID": "slides/slides3.html#example-in-the-assignment",
    "href": "slides/slides3.html#example-in-the-assignment",
    "title": "Control Variables",
    "section": "Example in the assignment",
    "text": "Example in the assignment\n\n\n\n\n\n\n\nmeasurement_error\n\n  \n\nPerformance\n\n Performance   \n\nCSR_report\n\n CSR_report   \n\nPerformance->CSR_report\n\n    \n\nScandals\n\n Scandals   \n\nPerformance->Scandals\n\n    \n\nReturn\n\n Return   \n\nCSR_report->Return\n\n    \n\nObserved_Report\n\n Observed_Report   \n\nCSR_report->Observed_Report"
  },
  {
    "objectID": "slides/slides3.html#simulation-bad-control",
    "href": "slides/slides3.html#simulation-bad-control",
    "title": "Control Variables",
    "section": "Simulation Bad Control",
    "text": "Simulation Bad Control\n\nCausal GraphSimulateResults\n\n\n\n\n\n\n\n\n\nconfounder\n\n  \n\nCorporateGovernance\n\n CorporateGovernance   \n\nPerformance\n\n Performance   \n\nCorporateGovernance->Performance\n\n    \n\nMarketReturn\n\n MarketReturn   \n\nCorporateGovernance->MarketReturn\n\n    \n\nPerformance->MarketReturn\n\n   \n\n\n\n\n\n\n\n\nd <- tibble(corp_gov = rnorm(N, 0, 1)) %>%\n  mutate(acc_profit = rnorm(N, corp_gov, sd = 3),\n         market_return = rnorm(N, 2 * corp_gov + acc_profit,\n                               sd = 3))\nlm1 <- lm(acc_profit ~ corp_gov, data = d)\nlm2 <- lm(acc_profit ~ corp_gov + market_return, data = d)\n\n\n\n\nmsummary(list(lm1, lm2),\n         gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    0.039 \n    0.012 \n  \n  \n     \n    (0.042) \n    (0.030) \n  \n  \n    corp_gov \n    1.000*** \n    −0.489*** \n  \n  \n     \n    (0.042) \n    (0.037) \n  \n  \n    market_return \n     \n    0.498*** \n  \n  \n     \n     \n    (0.007) \n  \n  \n    Num.Obs. \n    5000 \n    5000 \n  \n  \n    R2 \n    0.101 \n    0.551 \n  \n  \n    F \n    561.193 \n    3067.871 \n  \n  \n    RMSE \n    2.98 \n    2.11 \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides3.html#survival-bias",
    "href": "slides/slides3.html#survival-bias",
    "title": "Control Variables",
    "section": "Survival Bias",
    "text": "Survival Bias\n\nSimulateResults\n\n\n\nd <- mutate(d, survival = if_else(market_return > 5, 1, 0))\n\n\n\n\nlm1 <- lm(acc_profit ~ corp_gov, data = filter(d, survival == 1))\nlm2 <- lm(acc_profit ~ corp_gov * survival, data = d)\nmsummary(list(lm1, lm2), gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    3.518*** \n    −0.549*** \n  \n  \n     \n    (0.115) \n    (0.043) \n  \n  \n    corp_gov \n    −0.137 \n    0.606*** \n  \n  \n     \n    (0.095) \n    (0.045) \n  \n  \n    survival \n     \n    4.067*** \n  \n  \n     \n     \n    (0.135) \n  \n  \n    corp_gov × survival \n     \n    −0.743*** \n  \n  \n     \n     \n    (0.115) \n  \n  \n    Num.Obs. \n    853 \n    5000 \n  \n  \n    R2 \n    0.002 \n    0.262 \n  \n  \n    F \n    2.090 \n    592.341 \n  \n  \n    RMSE \n    2.43 \n    2.70 \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\n\n\n\nOne interpretation is that a firm can survive by being lucky (and having high returns) and by having good corporate governance (which translates in high returns). The survivors all are more likely to be having good corporate governance and there is little that can be explained further."
  },
  {
    "objectID": "slides/slides3.html#visualisation-of-colliders-and-interactions",
    "href": "slides/slides3.html#visualisation-of-colliders-and-interactions",
    "title": "Control Variables",
    "section": "Visualisation of Colliders (and Interactions)",
    "text": "Visualisation of Colliders (and Interactions)\n\n\n\n\nFull SampleSurvival HighlightedSurvival Only"
  },
  {
    "objectID": "slides/slides3.html#pitching-format",
    "href": "slides/slides3.html#pitching-format",
    "title": "Control Variables",
    "section": "Pitching Format",
    "text": "Pitching Format\n\n\n\nDescription (Important)\n\nTitle\nResearch Question\nKey Paper\nMotivation\n\nTHREE (IDioT) (Important)\n\nIdea\nData\nTools"
  },
  {
    "objectID": "slides/slides3.html#pitching-format-1",
    "href": "slides/slides3.html#pitching-format-1",
    "title": "Control Variables",
    "section": "Pitching Format",
    "text": "Pitching Format\n\n\n\nDescription (Important)\n\nTitle\nResearch Question\nKey Paper\nMotivation\n\nTHREE (IDioT) (Important)\n\nIdea\nData\nTools\n\n\n\n\nTWO\n\nWhat’s new?\nSo what?\n\nONE contribution\nOther considerations."
  },
  {
    "objectID": "slides/slides4.html#did-we-not-cover-that-already",
    "href": "slides/slides4.html#did-we-not-cover-that-already",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Did we not cover that already?",
    "text": "Did we not cover that already?\n\nYes, but briefly\nYes, but starting from the perspective of a regression (and the code)\n\n\nThe regression perspective is not bad. It means that we can see that more advanced regression techniques can be implemented in our linear regression framework. It’s also how most researchers in accounting and finance have been thought to think about research methods. However, there is a shift coming from economics where the focus is more on the research design."
  },
  {
    "objectID": "slides/slides4.html#the-focus-is-on-research-design",
    "href": "slides/slides4.html#the-focus-is-on-research-design",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "The focus is on Research Design",
    "text": "The focus is on Research Design\n\n\n\n\n\n\nImportant\n\n\n\nWhich data should we use?\nWhich comparison identifies the effect that we are interested in?\n\n\n\n\n\n\nIs there sufficient variation that can identify the effect. - See also the pitching document - A specific example is the identification of performance effects\n\n\n\nFor instance Alcohol and Mortality, Chapter 5 in Huntington-Klein (2021).\nIs there sufficient variation in the treatment and the outcome?\nAre we reasonably sure that there are no confounders or only a few and we can measure them?"
  },
  {
    "objectID": "slides/slides4.html#prevously-we-used-models-and-assumptions-to-identify-effects",
    "href": "slides/slides4.html#prevously-we-used-models-and-assumptions-to-identify-effects",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Prevously, we used models and assumptions to identify effects",
    "text": "Prevously, we used models and assumptions to identify effects\n\n\nMathematical models\n\\[\nV = T^{\\alpha_T} \\Bigl( \\frac{K}{\\alpha_K} \\Bigl)^{\\alpha_K}\n                 \\Bigl( \\frac{L}{\\alpha_L} \\Bigl)^{\\alpha_L}\n\\] \\[\n\\alpha_T + \\alpha_K + \\alpha_L = 1\n\\]\n\n\\(V =\\) The value of the firm\n\\(K =\\) Capital of the firm\n\\(L =\\) Labour of the firm\n\\(T =\\) CEO talent/skills/ability/experience\n\n\n\n\nDAGs\n\n\n\n\n\n\n\nspeedboat\n\n  \n\nave_ability\n\n ave_ability   \n\nltime\n\n ltime   \n\nave_ability->ltime\n\n    \n\nmixed_race\n\n mixed_race   \n\nmixed_race->ltime\n\n    \n\nfemale\n\n female   \n\nfemale->ave_ability\n\n    \n\nfemale->ltime\n\n    \n\ncourse\n\n course   \n\ncircumstances\n\n circumstances   \n\ncourse->circumstances\n\n    \n\nmonth_location\n\n month_location   \n\nmonth_location->circumstances\n\n    \n\ncircumstances->ltime\n\n    \n\ncircumstances->female"
  },
  {
    "objectID": "slides/slides4.html#just-focus-on-a-setting-where-we-are-confident-in-the-assumptions",
    "href": "slides/slides4.html#just-focus-on-a-setting-where-we-are-confident-in-the-assumptions",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Just focus on a setting where we are confident in the assumptions",
    "text": "Just focus on a setting where we are confident in the assumptions\n\n\nActual random assignment\nSpeedboat racing, game shows, Vietnam draft\nNatural experiments\nSee Gippel, Smith, and Zhu (2015), Chapter 19 Instrumental Variables in Huntington-Klein (2021)\n\nPolicy Changes\nChapter 18, Difference-in-Difference in Huntington-Klein (2021)\nDiscrete cutoffs\ne.g. WAM > 75, Chapter 20 Regression Continuity Design in Huntington-Klein (2021)\nUnexpected news\nChapter 17 Event Studies in Huntington-Klein (2021)\n\n\n\nNatural experiments is not the best terminology because most of these instances are not natural nor real experiments. Nevertheless, I still prefer the name over an instrumental variable approach. In too many proposals, I read an off hand comment that the student proposes to use a robustness test where they are going to use an instrumental variable approach. My answer to that is (1) if you have a natural experiment where you can exploit an instrumental variable, this should be the main analysis and (2) instrumental variables need to be defended as a research design based on your understanding of the setting. Calling the design a natural experiment forces you to think more about the experiment (i.e. the research design)."
  },
  {
    "objectID": "slides/slides4.html#look-for-these-designs",
    "href": "slides/slides4.html#look-for-these-designs",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Look for these designs!",
    "text": "Look for these designs!\n\n\nBased on your understanding of the industry and setting or the Data Generating Process\nWhen you read good papers for this unit and other units.\n\n\n\nThis is one of the main reasons that I want you to read broadly. It is unlikely that you will find a paper with a good research design exactly for the research question that you are interested in. However, you might find inspiration in similar or related fields that help you to design a better study for the research question that you are interested in."
  },
  {
    "objectID": "slides/slides4.html#what-effect-can-we-identify",
    "href": "slides/slides4.html#what-effect-can-we-identify",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "What effect can we identify?",
    "text": "What effect can we identify?\n\nAverage Treatment Effect\nAverage Treatment on the Treated\nAverage Treatment on the Untreated\nLocal Average Treatment Effect\nWeigthed Average Treatment Effect\n\nChapter 10, Treatment Effects in Huntington-Klein (2021)\n\n\nDo you have an example of an effect that we might be interested in in Accounting and Finance?\nAverage implies that not all firms will respond the same to the treatment. This is the source of a lot trouble.\nAverage over which population?\nHow would you put these different effects in your own words?\nWATE is evil and I am going to largely ignore it."
  },
  {
    "objectID": "slides/slides4.html#it-all-depends-on-where-the-variation-is-coming-from.",
    "href": "slides/slides4.html#it-all-depends-on-where-the-variation-is-coming-from.",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "It all depends on where the variation is coming from.",
    "text": "It all depends on where the variation is coming from.\n\n\n\n\n\n\nWarning\n\n\nDifferent firms react differently and are differently represented in the control group and the treatment group.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWith actual random assignment, you probably have an ATE for the population that received the assignment.\nIf you can use a control group because that is what the treated group would look like if they were not treated, you probably have an ATT.\nIf you use a natural experiment to identify part of the variation, you probably have a LATE.\n\n\n\n\nChapter 10, Treatment Effects in Huntington-Klein (2021)"
  },
  {
    "objectID": "slides/slides4.html#why-do-we-care",
    "href": "slides/slides4.html#why-do-we-care",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Why do we care?",
    "text": "Why do we care?\n\n\n\n\n\n\nResearch Design\n\n\nThere is a deep connection between the variation in your research design and the effect you can identify.\n\n\n\n\n\n\n\n\n\n\nPolicy Implications\n\n\nWhether your study has implications for “regulators and investors” depends heavily on the type of effect you can identify.\n\n\n\nChapter 10, Treatment Effects in Huntington-Klein (2021)\n\nThat is the setting of your data determines which research design you can use. The research design determines which effect you can identify. The effect you can identify determines which conclusions you can draw."
  },
  {
    "objectID": "slides/slides4.html#generate-the-data",
    "href": "slides/slides4.html#generate-the-data",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Generate the Data",
    "text": "Generate the Data\n\nN <- 1000\nrd1 <- tibble(\n  firm = 1:N,\n  high_performance = rbinom(N, 1, 0.5),\n  noise = rnorm(N, 0, 3)\n) %>%\n  mutate(\n    donation = high_performance,\n    performance = ifelse(high_performance == 1, 4, 1),\n    payoff_donation = 4 - 8 / performance + noise,\n    payoff_no_donation = 1 + noise\n  )\nglimpse(rd1) \n\nRows: 1,000\nColumns: 7\n$ firm               <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, …\n$ high_performance   <int> 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0…\n$ noise              <dbl> -0.53941291, 4.39811181, 5.1476…\n$ donation           <int> 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0…\n$ performance        <dbl> 1, 4, 1, 4, 4, 4, 4, 4, 4, 1, 1…\n$ payoff_donation    <dbl> -4.5394129, 6.3981118, 1.147609…\n$ payoff_no_donation <dbl> 0.4605871, 5.3981118, 6.1476092…\n\n\n\n\nWhat is the effect that we are we interested in?\nWhat are the policy implications?"
  },
  {
    "objectID": "slides/slides4.html#have-a-look-at-the-data",
    "href": "slides/slides4.html#have-a-look-at-the-data",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Have a look at the data",
    "text": "Have a look at the data\n\n\nWe will talk more about the pivot_wider and pivot_longer functions in week 7."
  },
  {
    "objectID": "slides/slides4.html#have-a-second-look-at-the-data",
    "href": "slides/slides4.html#have-a-second-look-at-the-data",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Have a second look at the data",
    "text": "Have a second look at the data"
  },
  {
    "objectID": "slides/slides4.html#real-data-does-not-have-the-counterfactuals.-we-only-observe-blue",
    "href": "slides/slides4.html#real-data-does-not-have-the-counterfactuals.-we-only-observe-blue",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Real data does not have the counterfactuals. We only observe blue!",
    "text": "Real data does not have the counterfactuals. We only observe blue!\n\n\n\n\n\n\n\nNote\n\n\nThe actual sample determines which comparisons we can make.\n\n\n\n\nWhy does this work? What effect are we identifying and how."
  },
  {
    "objectID": "slides/slides4.html#lets-redo-the-simulated-example-with-averages",
    "href": "slides/slides4.html#lets-redo-the-simulated-example-with-averages",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Let’s redo the simulated example with averages",
    "text": "Let’s redo the simulated example with averages\n\nrd1 %>%\n  mutate(causal_effect = payoff_donation - payoff_no_donation) %>%\n  summarise(M_causal = mean(causal_effect),\n            sd_causal = sd(causal_effect),\n            N = n()) %>%\n  knitr::kable(format = \"markdown\", digits = 2)\n\n\n\n\nM_causal\nsd_causal\nN\n\n\n\n\n-2.02\n3\n1000\n\n\n\n\n\n\n\nThe causal effect of donating for each firm is difference in payoff between donating and not donating.\nWhat effect are we estimating here?"
  },
  {
    "objectID": "slides/slides4.html#lets-redo-the-simulated-example-with-averages-1",
    "href": "slides/slides4.html#lets-redo-the-simulated-example-with-averages-1",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Let’s redo the simulated example with averages",
    "text": "Let’s redo the simulated example with averages\n\n\n\n\n\nM_causal\nsd_causal\nN\n\n\n\n\n-2.02\n3\n1000\n\n\n\n\n\n\nrd1 %>%\n  mutate(causal_effect = payoff_donation - payoff_no_donation) %>%\n  group_by(donation) %>%\n  summarise(M_causal = mean(causal_effect),\n            sd_causal = sd(causal_effect),\n            N = n()) %>%\n  knitr::kable(format = \"markdown\", digits = 2)\n\n\n\n\ndonation\nM_causal\nsd_causal\nN\n\n\n\n\n0\n-5\n0\n504\n\n\n1\n1\n0\n496"
  },
  {
    "objectID": "slides/slides4.html#lets-redo-the-regression-with-averages",
    "href": "slides/slides4.html#lets-redo-the-regression-with-averages",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Let’s redo the regression with averages",
    "text": "Let’s redo the regression with averages\n\nsummary_data  <- rd1 %>%\n  group_by(donation) %>%\n  summarise(M_payoff_donation = mean(payoff_donation),\n            M_payoff_no_donation = mean(payoff_no_donation))\nknitr::kable(summary_data, format = \"markdown\", digits = 2)\n\n\n\n\ndonation\nM_payoff_donation\nM_payoff_no_donation\n\n\n\n\n0\n-3.99\n1.01\n\n\n1\n1.87\n0.87\n\n\n\n\ncausal_effect_true <-\n  summary_data$M_payoff_donation[summary_data$donation == 1] -\n  summary_data$M_payoff_no_donation[summary_data$donation == 1]\ncausal_effect_reg <-\n  summary_data$M_payoff_donation[summary_data$donation == 1] -\n  summary_data$M_payoff_no_donation[summary_data$donation == 0]\n\n\n\n\n\n\n\nNote\n\n\n\nThe true ATT is 1\nThe effect estimated by the regression is 0.861"
  },
  {
    "objectID": "slides/slides4.html#if-you-do-not-believe-me-here-is-the-regression",
    "href": "slides/slides4.html#if-you-do-not-believe-me-here-is-the-regression",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "If you do not believe me, here is the regression",
    "text": "If you do not believe me, here is the regression\n\n\n\nrd1 <- mutate(rd1, actual_payoff =\n       ifelse(donation, payoff_donation, payoff_no_donation))\nols <- feols(actual_payoff ~ donation, data = rd1)\n\n\n\n\n\n\n \n  \n      \n     (1) \n  \n \n\n  \n    (Intercept) \n    1.007*** \n  \n  \n     \n    (0.135) \n  \n  \n    donation \n    0.861*** \n  \n  \n     \n    (0.192) \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides4.html#what-could-possibly-go-wrong",
    "href": "slides/slides4.html#what-could-possibly-go-wrong",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "What could possibly go wrong?",
    "text": "What could possibly go wrong?\n\nrd2 <- tibble(\n  high_performance = rbinom(N, 1, 0.5),\n  noise = rnorm(N, 0, 3)) %>%\n  mutate(\n    donation = high_performance,\n    performance = ifelse(high_performance == 1, 4, 1),\n    payoff_donation = 4 - 8 / performance + noise,\n    payoff_no_donation = ifelse(high_performance == 1, 1, 2) + noise\n  )"
  },
  {
    "objectID": "slides/slides4.html#causal-effect-estimates-with-a-confounder",
    "href": "slides/slides4.html#causal-effect-estimates-with-a-confounder",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Causal Effect Estimates with a Confounder",
    "text": "Causal Effect Estimates with a Confounder\n\nsummary_data  <- rd2 %>%\n  group_by(donation) %>%\n  summarise(M_payoff_donation = mean(payoff_donation),\n            M_payoff_no_donation = mean(payoff_no_donation))\nknitr::kable(summary_data, format = \"markdown\", digits = 2)\n\n\n\n\ndonation\nM_payoff_donation\nM_payoff_no_donation\n\n\n\n\n0\n-3.95\n2.05\n\n\n1\n1.80\n0.80\n\n\n\n\ncausal_effect_true <-\n  summary_data$M_payoff_donation[summary_data$donation == 1] -\n  summary_data$M_payoff_no_donation[summary_data$donation == 1]\ncausal_effect_reg <-\n  summary_data$M_payoff_donation[summary_data$donation == 1] -\n  summary_data$M_payoff_no_donation[summary_data$donation == 0]\n\n\nThe true ATT is 1\nThe effect estimated by the regression is -0.256"
  },
  {
    "objectID": "slides/slides4.html#where-is-the-variation-coming-from",
    "href": "slides/slides4.html#where-is-the-variation-coming-from",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Where is the variation coming from?",
    "text": "Where is the variation coming from?\n\n\n\n\n\n\nWe need firms that make mistakes\n\n\n\nFirms that should donate but do not always do it.\nFirms that should not donate but sometimes donate."
  },
  {
    "objectID": "slides/slides4.html#panel-data-simulation-100-firms",
    "href": "slides/slides4.html#panel-data-simulation-100-firms",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Panel Data Simulation (100 firms)",
    "text": "Panel Data Simulation (100 firms)\n\nN <- 100\nrd_firm <- tibble(\n  firm = 1:N,\n  high_performance = rbinom(N, 1, 0.5),\n  other_payoff = rnorm(N, 0, 3)) %>%\n  mutate(\n    donation = high_performance,\n    performance = ifelse(high_performance == 1, 4, 1),\n    payoff_no_donation = ifelse(high_performance == 1, 1, 2) + other_payoff,\n    payoff_donation = 4 - 8/performance + other_payoff\n  )\nsummary_data  <- rd_firm %>%\n  group_by(donation) %>%\n  summarise(M_payoff_donation = mean(payoff_donation),\n            M_payoff_no_donation = mean(payoff_no_donation))\nknitr::kable(summary_data, digits = 1)\n\n\n\n \n  \n    donation \n    M_payoff_donation \n    M_payoff_no_donation \n  \n \n\n  \n    0 \n    -4.3 \n    1.7 \n  \n  \n    1 \n    1.7 \n    0.7"
  },
  {
    "objectID": "slides/slides4.html#panel-data-simulation-10-time-periods",
    "href": "slides/slides4.html#panel-data-simulation-10-time-periods",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Panel Data Simulation (10 time periods)",
    "text": "Panel Data Simulation (10 time periods)\nThe variation comes from high performers not donating some years\n\nT <- 10\nrd_panel_forget <- tibble(\n  firm = rep(1:N, each = T),\n  year = rep(1:T, times = N)) %>%\n  left_join(rd_firm, by = \"firm\") %>%\n  mutate(forget_donation = rbinom(N * T, 1, plogis(-other_payoff)),\n         actual_donation = (1 - forget_donation) * donation,\n         actual_payoff = ifelse(actual_donation == 1,\n                                payoff_donation, payoff_no_donation))\n\n\n\nThe way we simulate the data reflects the firm fixed effects and the time varying effects.\nWhich effect are we identifying with this sample?"
  },
  {
    "objectID": "slides/slides4.html#the-new-assignment",
    "href": "slides/slides4.html#the-new-assignment",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "The New Assignment",
    "text": "The New Assignment\n\nRun a fixed effect model and interpret the result\nCreate a new dataset where all firms make mistakes\nRun a fixed effect model and interpret the result"
  },
  {
    "objectID": "slides/slides4.html#causal-diagram",
    "href": "slides/slides4.html#causal-diagram",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Causal Diagram",
    "text": "Causal Diagram\n\n\n\n\n\n\n\n\n\nrandomisation\n\n  \n\nx\n\n x   \n\ny\n\n y   \n\nx->y\n\n    \n\ncollider\n\n collider   \n\nx->collider\n\n    \n\ny->collider\n\n    \n\nconfounder\n\n confounder   \n\nconfounder->x\n\n    \n\nconfounder->y"
  },
  {
    "objectID": "slides/slides4.html#causal-diagram-1",
    "href": "slides/slides4.html#causal-diagram-1",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Causal Diagram",
    "text": "Causal Diagram\n\n\n\n\n\n\n\n\n\nrandomisation\n\n  \n\nx\n\n x   \n\ny\n\n y   \n\nx->y\n\n    \n\ncollider\n\n collider   \n\nx->collider\n\n    \n\ny->collider\n\n    \n\nconfounder\n\n confounder   \n\nconfounder->x\n\n    \n\nconfounder->y\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\nrandomisation\n\n  \n\nx\n\n x   \n\ny\n\n y   \n\nx->y\n\n    \n\ncollider\n\n collider   \n\nx->collider\n\n    \n\ny->collider\n\n    \n\niv\n\n iv   \n\niv->x\n\n    \n\nrandom\n\n random   \n\nrandom->iv\n\n    \n\nconfounder\n\n confounder   \n\nconfounder->x\n\n    \n\nconfounder->y\n\n   \n\n\n\n\n\n\n\nSee Instrumental Variables, Chapter 19 in Huntington-Klein (2021).\n\nMechanically, there are two regressions. (2-stage-least-squares) 1. Use the IV to estimate the randomly generated variation in X -> fitted(X) 2. Use fitted(X) to estimate the effect of random variation in X on Y"
  },
  {
    "objectID": "slides/slides4.html#simulation-and-implementation-with-fixest",
    "href": "slides/slides4.html#simulation-and-implementation-with-fixest",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Simulation and Implementation with fixest",
    "text": "Simulation and Implementation with fixest\n\n#|label: simulation-iv\nd <- tibble(\n  iv = rnorm(N, 0, 1),\n  confounder = rnorm(N, 0, 1)) %>%\n  mutate(\n    x = rnorm(N, .6 * iv - .6 * confounder, .6),\n    y = rnorm(N, .6 * x + .6 * confounder, .6),\n    survival = if_else(y > 0, 1, 0)\n  )\nsurv <- filter(d, survival == 1)\nlm1 <- lm(y ~ x, d)\nlm2 <- lm(y ~ x + confounder, d)\nlm3 <- lm(y ~ x, surv)\nlm4 <- lm(y ~ x + confounder, surv)\niv1 <- feols(y ~ 1 | 0 | x ~ iv, data = d)\niv2 <- feols(y ~ 1 | 0 | x ~ iv, data = surv)\n\n\nAll the exogenous variable are in the tibble statement, all the endogenous variables are in the mutate statement. That is not a coincidence. It also highlights the value and tight link between being able to simulate your theory and understanding it.\nNote, the collider bias is the biggest problem if the selection bias is on both x and y because then the collider bias effects the first stage regressions."
  },
  {
    "objectID": "slides/slides4.html#simulation-results-with-a-real-effect-of-0.6",
    "href": "slides/slides4.html#simulation-results-with-a-real-effect-of-0.6",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Simulation results with a real effect of 0.6",
    "text": "Simulation results with a real effect of 0.6\n\nmsummary(list(\"confounded\" = lm1, \"with control\" = lm2, \"collider\" = lm3, \"collider\" = lm4,\n              \"iv no collider\" = iv1, \"iv with collider\" = iv2),\n         gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n    confounded \n    with control \n    collider \n    collider  \n    iv no collider \n    iv with collider \n  \n \n\n  \n    (Intercept) \n    −0.047 \n    0.002 \n    0.623*** \n    0.494*** \n    −0.098 \n    0.477*** \n  \n  \n     \n    (0.078) \n    (0.061) \n    (0.071) \n    (0.072) \n    (0.107) \n    (0.121) \n  \n  \n    x \n    0.232*** \n    0.535*** \n    0.127* \n    0.299*** \n     \n     \n  \n  \n     \n    (0.078) \n    (0.072) \n    (0.074) \n    (0.079) \n     \n     \n  \n  \n    confounder \n     \n    0.537*** \n     \n    0.279*** \n     \n     \n  \n  \n     \n     \n    (0.067) \n     \n    (0.074) \n     \n     \n  \n  \n    fit_x \n     \n     \n     \n     \n    0.939*** \n    0.574** \n  \n  \n     \n     \n     \n     \n     \n    (0.219) \n    (0.244) \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\nThis is not strictly a collider because there is no effect of x on survival. However, it already shows that there are problems with “simple” selection bias."
  },
  {
    "objectID": "slides/slides4.html#simulation-without-an-effect",
    "href": "slides/slides4.html#simulation-without-an-effect",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Simulation without an effect",
    "text": "Simulation without an effect\n\nd <- tibble(\n  iv = rnorm(N, 0, 1),\n  confounder = rnorm(N, 0, 1)) %>%\n  mutate(\n    x = rnorm(N, .6 * iv - .6 * confounder, .6),\n    y = rnorm(N, .6 * confounder, .6),\n    survival = if_else(y > 0, 1, 0)\n  )\nsurv <- filter(d, survival == 1)\nlm1 <- lm(y ~ x, d)\nlm2 <- lm(y ~ x + confounder, d)\nlm3 <- lm(y ~ x, surv)\nlm4 <- lm(y ~ x + confounder, surv)\niv1 <- feols(y ~ 1 | 0 | x ~ iv, data = d)\niv2 <- feols(y ~ 1 | 0 | x ~ iv, data = surv)"
  },
  {
    "objectID": "slides/slides4.html#simulation-without-an-effect-1",
    "href": "slides/slides4.html#simulation-without-an-effect-1",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Simulation without an effect",
    "text": "Simulation without an effect\n\nmsummary(list(\"confounded\" = lm1, \"with control\" = lm2, \"collider\" = lm3, \"collider\" = lm4,\n              \"iv no collider\" = iv1, \"iv with collider\" = iv2),\n         gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n    confounded \n    with control \n    collider \n    collider  \n    iv no collider \n    iv with collider \n  \n \n\n  \n    (Intercept) \n    0.104 \n    0.055 \n    0.724*** \n    0.534*** \n    0.096 \n    0.744*** \n  \n  \n     \n    (0.078) \n    (0.056) \n    (0.068) \n    (0.080) \n    (0.091) \n    (0.073) \n  \n  \n    x \n    −0.378*** \n    0.008 \n    −0.127** \n    0.003 \n     \n     \n  \n  \n     \n    (0.068) \n    (0.063) \n    (0.061) \n    (0.066) \n     \n     \n  \n  \n    confounder \n     \n    0.634*** \n     \n    0.322*** \n     \n     \n  \n  \n     \n     \n    (0.066) \n     \n    (0.088) \n     \n     \n  \n  \n    fit_x \n     \n     \n     \n     \n    0.045 \n    −0.074 \n  \n  \n     \n     \n     \n     \n     \n    (0.142) \n    (0.092) \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides4.html#examplesitting-duck-governors-by-falk2018",
    "href": "slides/slides4.html#examplesitting-duck-governors-by-falk2018",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Example:Sitting Duck Governors by Falk and Shelton (2018)",
    "text": "Example:Sitting Duck Governors by Falk and Shelton (2018)\n\n\n\n\n\n\nNote\n\n\n\nResearch Question: Does political uncertainty effect investment?\nMore uncertainty in a state when governor does not come up for reelection.\nState level laws with term limits (~ Random)\n\n\n\n\n\nAn exercise to be run in class"
  },
  {
    "objectID": "slides/slides4.html#data",
    "href": "slides/slides4.html#data",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Data",
    "text": "Data\n\nlibrary(readit)\nduck <- readit(here(\"data\", \"LameDuckData.dta\")) %>%\n  select(-starts_with(\"nstate\"), -starts_with(\"stdum\"),\n         -starts_with(\"yd_alt\")) %>%\n  group_by(statename) %>%\n  arrange(year) %>%\n  mutate(log_I_1 = lag(log_I), log_I_2 = lag(log_I, 2),\n         log_Y_1 = lag(log_Y), log_Y_2 = lag(log_Y, 2),\n         log_real_GDP_1 = lag(log_real_GDP),\n         log_real_GDP_2 = lag(log_real_GDP, 2)) %>%\n  ungroup() %>%\n  arrange(statename) %>%\n  filter(year >= 1967, year <= 2004)"
  },
  {
    "objectID": "slides/slides4.html#reduced-form",
    "href": "slides/slides4.html#reduced-form",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Reduced Form",
    "text": "Reduced Form\n\nform_red <- formula(\n  log_I ~ gov_exogenous_middling + log_I_1 + log_I_2 +\n  log_Y + log_Y_1 + log_Y_2 + log_real_GDP + log_real_GDP_1 +\n  log_real_GDP_2 | statename\n  )\nred_reg <- feols(form_red, data = duck)"
  },
  {
    "objectID": "slides/slides4.html#stage-least-squares-2sls",
    "href": "slides/slides4.html#stage-least-squares-2sls",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "2 Stage Least Squares (2SLS)",
    "text": "2 Stage Least Squares (2SLS)\n\nform_iv <- formula(log_I ~ log_I_1 + log_I_2 +\n  log_Y + log_Y_1 + log_Y_2 + log_real_GDP + log_real_GDP_1 +\n  log_real_GDP_2\n  # fixed effects\n  | statename\n  # 1st regression\n  | uncertainty_continuous ~ gov_exogenous_middling\n  )\niv_reg <- feols(form_iv, data = duck)"
  },
  {
    "objectID": "slides/slides4.html#results",
    "href": "slides/slides4.html#results",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Results",
    "text": "Results\n\ncoef_map = c(\"gov_exogenous_middling\" = \"lame duck governor\",\n             \"fit_uncertainty_continuous\" = \"uncertainty\")\nmsummary(list(\"reduced\" = red_reg,\n              \"first stage iv\" = summary(iv_reg, stage = 1),\n              \"second stage iv\" = iv_reg),\n         gof_omit = gof_omit, stars = stars,\n         coef_map = coef_map)\n\n\n\n \n  \n      \n    reduced \n    first stage iv \n    second stage iv \n  \n \n\n  \n    lame duck governor \n    −0.049** \n    1.801*** \n     \n  \n  \n     \n    (0.021) \n    (0.112) \n     \n  \n  \n    uncertainty \n     \n     \n    −0.027** \n  \n  \n     \n     \n     \n    (0.012) \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides4.html#diagnostics-test-for-endogeneity-durbin-wu-hausmann",
    "href": "slides/slides4.html#diagnostics-test-for-endogeneity-durbin-wu-hausmann",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Diagnostics: Test for endogeneity (Durbin-Wu-Hausmann)",
    "text": "Diagnostics: Test for endogeneity (Durbin-Wu-Hausmann)\n\n\n\n\n\n\nNote\n\n\nIs the IV result different from the OLS result?\n\n\n\n\nsumm_iv <- summary(iv_reg)\nsumm_1st <- summary(iv_reg, stage = 1)\nsumm_iv$iv_wh$stat  # iv wu hausmann\n\n[1] 3.829033\n\nsumm_iv$iv_wh$p     # iv wu hausmann\n\n[1] 0.05054677\n\n\nInstrumental Variables, Chapter 19 in Huntington-Klein (2021)"
  },
  {
    "objectID": "slides/slides4.html#diagnostics-test-for-weak-instrument",
    "href": "slides/slides4.html#diagnostics-test-for-weak-instrument",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Diagnostics: Test for weak instrument",
    "text": "Diagnostics: Test for weak instrument\n\n\n\n\n\n\nNote\n\n\nIs the instrument predicting the variable we want it to predict?\n\n\n\n\nfitstat(iv_reg, type = \"ivf\")\n\nF-test (1st stage), uncertainty_continuous: stat = 331.0, p < 2.2e-16, on 1 and 1,640 DoF."
  },
  {
    "objectID": "slides/slides4.html#new-assignment",
    "href": "slides/slides4.html#new-assignment",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "New Assignment",
    "text": "New Assignment\nLet’s assume that firms are less likely to donate when there is a local election\n\nN <- 5000\nrd_iv_el <- tibble(\n  high_performance = rbinom(N, 1, .5),\n  extra_payoff = rnorm(N, 0, 3),\n  local_election = rbinom(N, 1, .33)) %>%\n  mutate(\n    actual_donation = ifelse(high_performance == 1, 1 - local_election, 0),\n    payoff_donation = ifelse(high_performance == 1, 2, - 4) + extra_payoff,\n    payoff_no_donation = ifelse(high_performance == 1, 1, 2) + extra_payoff,\n    actual_payoff = ifelse(actual_donation == 1,\n                           payoff_donation, payoff_no_donation))\n\n\n\nWhich effect can we identify with this data?\nRun the instrumental variable analyses and interpret the results."
  },
  {
    "objectID": "slides/slides4.html#this-paper-is-a-finished-product-your-pitch-proposal-or-dissertation-is-not.",
    "href": "slides/slides4.html#this-paper-is-a-finished-product-your-pitch-proposal-or-dissertation-is-not.",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "This paper is a finished product, your pitch, proposal, or dissertation is not.",
    "text": "This paper is a finished product, your pitch, proposal, or dissertation is not.\nWe are grateful to Michael Roberts (the Editor), the Associate Editor, two anonymous referees, Marianne Bertrand, Ing-Haw Cheng, Ken French, Ed Glaeser, Todd Gormley, Ben Iverson (discus- sant), Steve Kaplan, Borja Larrain (discussant), Jonathan Lewellen, Katharina Lewellen, David Matsa (discussant), David Metzger (discussant), Toby Moskowitz, Candice Prendergast, Enrichetta Ravina (discussant), Amit Seru, and Wei Wang (discussant) for helpful suggestions. We thank seminar participants at AFA, BYU, CICF Conference, Depaul, Duke, Gerzensee ESSFM, Harvard, HKUST Finance Symposium, McGill Todai Conference, Finance UC Chile, Helsinki, IDC Herzliya Finance Conference, NBER Corporate Finance and Personnel Meetings, SEC, Simon Fraser Uni- versity, Stanford, Stockholm School of Economics, University of Amsterdam, UC Berkeley, UCLA, and Wharton for helpful comments. We thank David Yermack for his generosity in sharing data. We thank Matt Turner at Pearl Meyer, Don Delves at the Delves Group, and Stephen O’Byrne at Shareholder Value Advisors for helping us understand the intricacies of executive stock option plans. Menaka Hampole provided excellent research assistance. We acknowledge financial support from the Initiative on Global Markets.\n\nOn the one hand, we do not expect you to come up with a design like this. On the other hand, why not use these hard won insights."
  },
  {
    "objectID": "slides/slides4.html#this-paper-has-1-one-research-question.-this-is-a-good-thing",
    "href": "slides/slides4.html#this-paper-has-1-one-research-question.-this-is-a-good-thing",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "This paper has 1 (one!) research question. This is a good thing!",
    "text": "This paper has 1 (one!) research question. This is a good thing!\n\nIt’s not necessarily advantageous to have too many hypotheses. You want to answer one question well."
  },
  {
    "objectID": "slides/slides4.html#do-increases-in-option-grants-increase-risk-taking",
    "href": "slides/slides4.html#do-increases-in-option-grants-increase-risk-taking",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Do increases in option grants increase risk taking?",
    "text": "Do increases in option grants increase risk taking?\n\n\n\n\n\n\n\noptions\n\n  \n\nOption Grants\n\n Option Grants   \n\nRisk Taking\n\n Risk Taking   \n\nOption Grants->Risk Taking\n\n    \n\nAnnoyances\n\n Annoyances   \n\nAnnoyances->Option Grants\n\n    \n\nAnnoyances->Risk Taking\n\n   \n\n\n\n\n\n\nExample of annoyances: Risk averse CEOs might take less risks and therefore receive more option grants."
  },
  {
    "objectID": "slides/slides4.html#iv-1-scheduled-discrete-increases-in-fixed-value-option-grants",
    "href": "slides/slides4.html#iv-1-scheduled-discrete-increases-in-fixed-value-option-grants",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "IV 1: Scheduled Discrete Increases in Fixed-Value Option Grants",
    "text": "IV 1: Scheduled Discrete Increases in Fixed-Value Option Grants\n\n\n\n\n\n\n\noptions\n\n  \n\nPredicted New Grant Cycle\n\n Predicted New Grant Cycle   \n\nOption Grants\n\n Option Grants   \n\nPredicted New Grant Cycle->Option Grants\n\n    \n\nRisk Taking\n\n Risk Taking   \n\nOption Grants->Risk Taking\n\n    \n\nAnnoyances\n\n Annoyances   \n\nAnnoyances->Option Grants\n\n    \n\nAnnoyances->Risk Taking\n\n   \n\n\n\n\n\n\nFor our first instrument, we use fixed-value firms, for which option grants can increase only at regularly prescheduled intervals (i.e., when new cycles start). For example, consider a fixed-value firm on regular three-year cycles. Other time-varying factors may drive trends in risk for this firm. However, these trends are unlikely to coincide exactly with the timing of when new cycles are scheduled to start.\n\n\nBasically saying the beginning of a cycle effect on option grants is not affected by the annoyances."
  },
  {
    "objectID": "slides/slides4.html#iv-2-within-cycle-grant-increases-due-to-industry-shocks-in-fixed-number-option-grants",
    "href": "slides/slides4.html#iv-2-within-cycle-grant-increases-due-to-industry-shocks-in-fixed-number-option-grants",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "IV 2: Within Cycle Grant Increases due to Industry Shocks in Fixed-Number Option Grants",
    "text": "IV 2: Within Cycle Grant Increases due to Industry Shocks in Fixed-Number Option Grants\n\n\n\n\n\n\n\noptions\n\n  \n\nIndustry Shocks (Fixed Number)\n\n Industry Shocks (Fixed Number)   \n\nOption Grants\n\n Option Grants   \n\nIndustry Shocks (Fixed Number)->Option Grants\n\n    \n\nRisk Taking\n\n Risk Taking   \n\nOption Grants->Risk Taking\n\n    \n\nAnnoyances\n\n Annoyances   \n\nAnnoyances->Option Grants\n\n    \n\nAnnoyances->Risk Taking\n\n   \n\n\n\n\n\n\nFor our second instrument, we focus on fixed-number firms. The value of options granted in any particular year varies with aggregate returns within a fixed-number cycle. This means that the timing of increases in option pay within a cycle will be random in the sense that the increases are driven in part by industry shocks that are beyond the control of the firm and are largely unpredictable. To account for the possibility that aggregate returns can directly affect risk, we use fixed-value firms as a control group because their option compensation must remain fixed despite changes in aggregate returns.\n\n\nThe identifying assumption is that fixed-number vs fixed-value might be a part of the annoyances. So might the industry shocks. However, the IV assumes that the industry shocks are not different except in how they effect the option grant value."
  },
  {
    "objectID": "slides/slides4.html#the-authors-know-their-setting",
    "href": "slides/slides4.html#the-authors-know-their-setting",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "The authors know their setting!",
    "text": "The authors know their setting!\n\nOur identification strategy builds on Hall’s (1999)) observation that firms often award options according to multiyear plans. Two types of plans are commonly used: fixed-number and fixed-value. Under a fixed-number plan, an executive receives the same number of options each year within a cycle. Under a fixed-value plan, an executive receives the same value of options each year within a cycle.\n\n\n\nOur conversations with leading compensation consultants suggest that multiyear plans are used to minimize contracting costs, as option compensation only has to be set once every few years. Hall (1999, p. 97) argues that firms sort into the two types of plans somewhat arbitrarily, observing that “Boards seem to substitute one plan for another without much analysis or understanding of their differences.”\n\n\n\nRead qualitative studies and descriptions of actual practice!\nWe are looking at “slightly suboptimal” decision making to get variation."
  },
  {
    "objectID": "slides/slides4.html#key-assumption-1---relevance-iv-is-related-to-option-grants",
    "href": "slides/slides4.html#key-assumption-1---relevance-iv-is-related-to-option-grants",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Key Assumption 1 - Relevance: IV is related to Option Grants",
    "text": "Key Assumption 1 - Relevance: IV is related to Option Grants\n\nWe find that the first-year indicator corresponds to a 15% larger increase in the Black-Scholes value of new option grants than in other years.\n\n\nAll estimates are highly significant, with F-statistics greatly exceeding 10, the rule of thumb threshold for concerns related to weak instruments (Staiger and Stock (1997). (III A.)\n\nChapter 19 Instrumental Variables in Huntington-Klein (2021)"
  },
  {
    "objectID": "slides/slides4.html#key-assumption-2---exclusion-or-validity-only-path-from-iv-to-risk-taking-is-through-option-grants.",
    "href": "slides/slides4.html#key-assumption-2---exclusion-or-validity-only-path-from-iv-to-risk-taking-is-through-option-grants.",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "Key Assumption 2 - Exclusion (or validity): Only path from IV to Risk Taking is through Option Grants.",
    "text": "Key Assumption 2 - Exclusion (or validity): Only path from IV to Risk Taking is through Option Grants.\n\nOne might be concerned that predicted first years provide exogenously timed but potentially anticipated increases in option compensation. However, this is not an issue for our empirical strategy. […] He would have no incentive to increase risk prior to an anticipated increase in the value of his option compensation next period.\n\n\nIn addition, we directly examine whether fixed-value cycles appear to be correlated with other firm cycles […]\n\nChapter 19 Instrumental Variables in Huntington-Klein (2021)\n\nThe key for the exclusion assumption is that anticipation would have an impact on the risk taking prior to the new cycle. This than would have an impact on the actual measure, i.e. the change in risk."
  },
  {
    "objectID": "slides/slides4.html#one-criticism",
    "href": "slides/slides4.html#one-criticism",
    "title": "Research Design 1: Fixed Effects and Instrumental Variables",
    "section": "One Criticism",
    "text": "One Criticism\n\nFirst, option compensation tends to follow an increasing step function for executives on fixed-value plans. This is because compensation tends to drift upward over time, yet executives on fixed-value plans cannot experience an upward drift within a cycle.\n\n\nWhile these two stylized facts do not hold in all cases—as can also be seen in Figure 1—our identification strategy only requires that they hold on average.\n\n\n\n\n\n\n\n\nSome more terminology\n\n\n\nCompliers\nAlways-takers/never-takers\nDefiers\n\n\n\n\nChapter 19 Instrumental Variables in Huntington-Klein (2021)\n\nThe LATE is identified for the compliers. IV assumes that there are no defiers because now our estimated effect becomes an average of the defiers and compliers. One solution is to just remove the defiers if you can (which they do in the paper as a robustness check)."
  },
  {
    "objectID": "slides/slides5.html#a-basic-before---after-comparison",
    "href": "slides/slides5.html#a-basic-before---after-comparison",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "A basic before - after comparison",
    "text": "A basic before - after comparison\n\n\n\n\n\n\n\nevent\n\n  \n\nEvent Happened\n\n Event Happened   \n\nTreatment\n\n Treatment   \n\nEvent Happened->Treatment\n\n    \n\nOutcome\n\n Outcome   \n\nTreatment->Outcome\n\n    \n\nTime\n\n Time   \n\nTime->Event Happened\n\n    \n\nTime->Outcome\n\n   \n\n\n\n\n\nChapter 17 Event Studies in Huntington-Klein (2021)\n\nWhere Time could be standing in for a lot of other annoying things that might happen."
  },
  {
    "objectID": "slides/slides5.html#use-data-before-the-event-to-infer-the-counterfactual-outcome-in-yellow",
    "href": "slides/slides5.html#use-data-before-the-event-to-infer-the-counterfactual-outcome-in-yellow",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Use Data Before The Event to Infer The Counterfactual Outcome (in Yellow)",
    "text": "Use Data Before The Event to Infer The Counterfactual Outcome (in Yellow)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe do not observe the yellow/gold returns. We have to estimate them or convince the reader that there are no trends to be expected for theoretical/institutional reasons. I will not go into the details of the estimation here but I will in week 7."
  },
  {
    "objectID": "slides/slides5.html#front-running-information-leaking-and-anticipation-are-all-annoying.",
    "href": "slides/slides5.html#front-running-information-leaking-and-anticipation-are-all-annoying.",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Front-running, information leaking, and anticipation are all annoying.",
    "text": "Front-running, information leaking, and anticipation are all annoying.\n\n\n\n\n\n\n\nevent\n\n  \n\nBefore Block Trade\n\n Before Block Trade   \n\nLarge Block Trade\n\n Large Block Trade   \n\nBefore Block Trade->Large Block Trade\n\n    \n\nPrice Impact\n\n Price Impact   \n\nLarge Block Trade->Price Impact\n\n    \n\nTime\n\n Time   \n\nTime->Before Block Trade\n\n    \n\nTime->Price Impact\n\n   \n\n\n\n\n\n\n\n\nGo also back to Assignment 2 where we modeled the same problem when investors anticipate a donation.\n\n\n\nTo gauge demand from buyers and potentially gin up interest from sellers, bankers send out lists of shares with upcoming lockup expirations, according to market participants. (Money Stuff, Matt Levine)\nSometimes, bankers also engage in hypothetical conversations with buyers before they have a mandate. Asking prospective buyers whether they might be interested in certain stocks is one thing. But if there are indeed plans afoot for block sales, such conversations, even phrased hypothetically, can tip off savvy money managers. (Money Stuff, Matt Levine)"
  },
  {
    "objectID": "slides/slides5.html#what-if-we-had-an-additional-control-group-to-estimate-the-counterfactual",
    "href": "slides/slides5.html#what-if-we-had-an-additional-control-group-to-estimate-the-counterfactual",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "What if we had an additional control group to estimate the counterfactual?",
    "text": "What if we had an additional control group to estimate the counterfactual?"
  },
  {
    "objectID": "slides/slides5.html#a-simulated-cheap-talk-example-voluntary-disclosure-in-time-2",
    "href": "slides/slides5.html#a-simulated-cheap-talk-example-voluntary-disclosure-in-time-2",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "A Simulated Cheap Talk Example: Voluntary Disclosure in Time 2",
    "text": "A Simulated Cheap Talk Example: Voluntary Disclosure in Time 2\n\nN <- 500\nT <- 2\ntime_effect <- c(3.5, 0)\nrd_did_firm <- tibble(\n  firm = 1:N,\n  performance = runif(N, 1, 10),\n  firm_effect = rnorm(N, 0, 2) + ifelse(performance < 3, 3, 0)\n)\nrd_did_panel <- tibble(\n  firm = rep(1:N, each = T),\n  time = rep(1:T, times = N)) %>%\n  left_join(rd_did_firm, by = \"firm\") %>%\n  mutate(\n    report = ifelse(time == 2, ifelse(performance > 3, 1, 0), 0),\n    noise = rnorm(N*T, 0, 3),\n    profit_report = 6.5 + time_effect[time] + firm_effect + noise,\n    profit_no_report = 1.5 + time_effect[time] + firm_effect + noise,\n    actual_profit = ifelse(report == 1, profit_report, profit_no_report))\n\n\nThe idea is that we have firms who perform well (performance > 3) and firms that perform bad (performance < 3). The firms that perform well will voluntarily disclose a report in time 2. We can see the effect as the difference between time 1 and time 2 for disclosers and non-disclosers.\nImportant: the cost of misreporting is not in calculated in the profit. The reasoning would be that this might be a litigation cost that would only emerge later on."
  },
  {
    "objectID": "slides/slides5.html#the-causal-effects-in-our-simulation",
    "href": "slides/slides5.html#the-causal-effects-in-our-simulation",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "The Causal Effects in Our Simulation",
    "text": "The Causal Effects in Our Simulation\n\nrd_did_panel %>%\n  mutate(causal_effect = profit_report - profit_no_report) %>%\n  group_by(time, report2 = performance > 3) %>%\n  summarise(profit_report = mean(profit_report),\n            profit_no_report = mean(profit_no_report),\n            causal_effect = mean(causal_effect)) %>%\n  kable(digits = 1)\n\n\n\n \n  \n    time \n    report2 \n    profit_report \n    profit_no_report \n    causal_effect \n  \n \n\n  \n    1 \n    FALSE \n    12.5 \n    7.5 \n    5 \n  \n  \n    1 \n    TRUE \n    9.8 \n    4.8 \n    5 \n  \n  \n    2 \n    FALSE \n    9.9 \n    4.9 \n    5 \n  \n  \n    2 \n    TRUE \n    6.5 \n    1.5 \n    5"
  },
  {
    "objectID": "slides/slides5.html#a-summary-of-the-actual-profits",
    "href": "slides/slides5.html#a-summary-of-the-actual-profits",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "A Summary of The Actual Profits",
    "text": "A Summary of The Actual Profits\n\nrd_did_panel %>%\n  group_by(time, report2 = performance > 3) %>%\n  summarise(actual_profit = mean(actual_profit)) %>%\n  pivot_wider(names_from = time, values_from = actual_profit) %>%\n  kable(digits = 1)\n\n\n\n \n  \n    report2 \n    1 \n    2 \n  \n \n\n  \n    FALSE \n    7.5 \n    4.9 \n  \n  \n    TRUE \n    4.8 \n    6.5"
  },
  {
    "objectID": "slides/slides5.html#regressions",
    "href": "slides/slides5.html#regressions",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Regressions",
    "text": "Regressions\n\ndid_lm <- feols(actual_profit ~ report, data = rd_did_panel)\ndid_sub <- feols(actual_profit ~ report, data = filter(rd_did_panel, time == 2))\ndid_fixed <- feols(actual_profit ~ report | firm, data = rd_did_panel)\ndid_did <- feols(actual_profit ~ report | firm + time, data = rd_did_panel)\nmsummary(list(simple = did_lm, \"time 2\" = did_sub, \"firm FE\" = did_fixed, \"two-way FE\" = did_did),\n         gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n    simple \n     time 2 \n    firm FE \n    two-way FE \n  \n \n\n  \n    (Intercept) \n    5.283*** \n    4.874*** \n     \n     \n  \n  \n     \n    (0.148) \n    (0.337) \n     \n     \n  \n  \n    report \n    1.187*** \n    1.596*** \n    1.714*** \n    4.313*** \n  \n  \n     \n    (0.238) \n    (0.383) \n    (0.222) \n    (0.484) \n  \n  \n    Num.Obs. \n    1000 \n    500 \n    1000 \n    1000 \n  \n  \n    R2 \n    0.024 \n    0.034 \n    0.618 \n    0.646 \n  \n  \n    R2 Within \n     \n     \n    0.098 \n    0.144 \n  \n  \n    RMSE \n    3.66 \n    3.59 \n    2.29 \n    2.20 \n  \n  \n    Std.Errors \n    IID \n    IID \n    by: firm \n    by: firm \n  \n  \n    FE: firm \n     \n     \n    X \n    X \n  \n  \n    FE: time \n     \n     \n     \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides5.html#what-if-we-have-three-periods",
    "href": "slides/slides5.html#what-if-we-have-three-periods",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "What if we have three periods?",
    "text": "What if we have three periods?\n\n\n\n\n\n\nNote\n\n\nWe assume that over time investors and regulators get better at detecting when firms exaggerate in their report.\n\n\n\n\nTime 1: Reports are not believable, nobody reports\nTime 2: The biggest exaggerations will be caught, only well performing firms will report and communicate that they are doing excellent.\nTime 3: More subtle exaggerations will be caught. The worst performers will not report at all, the moderate performers will report and say that they will do well, the good performers will report that they are doing excellent.\n\n\n\nSee the Appendix of the assignment for the derivation of the exact parameters."
  },
  {
    "objectID": "slides/slides5.html#setup-of-three-period-simulation",
    "href": "slides/slides5.html#setup-of-three-period-simulation",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Setup of three period simulation",
    "text": "Setup of three period simulation\n\nN <- 1000\nT <- 3\ncutoff2 <- 3 # performance cutoff to report for time 1\ncutoff3 <- c(4/3, 4 + 2/3) # performance cutoff to report for time 2\nprofit1 <- 5\nprofit2 <- c(1.5, 6.5) #Profits for time 2 depending on report\nprofit3 <- c(2/3, 3, 7 + 1/3) #Profits for time 2 depending on report\nrd_did3_firm <- tibble(\n  firm = 1:N,\n  performance = runif(N, 0, 10),\n  firm_effect = rnorm(N, 0, 2) + ifelse(performance < cutoff2, 3, 0)\n)"
  },
  {
    "objectID": "slides/slides5.html#three-period-simulation",
    "href": "slides/slides5.html#three-period-simulation",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Three period simulation",
    "text": "Three period simulation\n\nrd_did3_panel <- tibble(\n  firm = rep(1:N, each = T),\n  time = rep(1:T, times = N)) %>%\n  left_join(rd_did3_firm, by = \"firm\") %>%\n  mutate(\n    # When will firms report?\n    report = case_when(\n      time == 1 ~ 0,\n      time == 2 & performance < cutoff2 ~ 0,\n      time == 3 & performance < cutoff3[1] ~ 0,\n      TRUE ~ 1),\n    noise = rnorm(T*N, 0, 5),\n    profit_no_report = firm_effect + noise +\n      case_when(\n        time == 1 ~ profit1,\n        time == 2 ~ profit2[1],\n        time == 3 ~ profit3[1]\n    ),\n    profit_report = firm_effect + noise +\n      case_when(\n        time == 1 ~ profit1,\n        time == 2 ~ profit2[2],\n        time == 3 & performance < cutoff3[2] ~ profit3[2],\n        TRUE ~ profit3[3]\n      ),\n    actual_profit = ifelse(report == 1, profit_report, profit_no_report)\n  )"
  },
  {
    "objectID": "slides/slides5.html#overview-of-4-groups-of-firms",
    "href": "slides/slides5.html#overview-of-4-groups-of-firms",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Overview of 4 groups of firms",
    "text": "Overview of 4 groups of firms\n\nNever reporters\nReporters in year 3\nReporters in year 2 and 3 (Medium)\nReporters in year 2 and 3 (High)\n\n\ncausal_effects <- rd_did3_panel %>%\n  mutate(causal_effect = profit_report - profit_no_report,\n         group = case_when(\n           performance < cutoff3[1] ~ 1,\n           performance < cutoff2 ~ 2,\n           performance < cutoff3[2] ~ 3,\n           TRUE ~ 4\n         )) %>%\n  group_by(time, group) %>%\n  summarise(report = mean(report),\n            N = n(),\n            M_report = mean(profit_report),\n            M_no_report = mean(profit_no_report),\n            M_causal_effect = mean(causal_effect))"
  },
  {
    "objectID": "slides/slides5.html#overview-of-4-groups-of-firms-1",
    "href": "slides/slides5.html#overview-of-4-groups-of-firms-1",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Overview of 4 groups of firms",
    "text": "Overview of 4 groups of firms\n\n\n\n\n \n  \n    time \n    group \n    report \n    N \n    M_report \n    M_no_report \n    M_causal_effect \n  \n \n\n  \n    1 \n    1 \n    0 \n    139 \n    7.6 \n    7.6 \n    0.0 \n  \n  \n    1 \n    2 \n    0 \n    173 \n    8.5 \n    8.5 \n    0.0 \n  \n  \n    1 \n    3 \n    0 \n    163 \n    4.8 \n    4.8 \n    0.0 \n  \n  \n    1 \n    4 \n    0 \n    525 \n    5.0 \n    5.0 \n    0.0 \n  \n  \n    2 \n    1 \n    0 \n    139 \n    8.8 \n    3.8 \n    5.0 \n  \n  \n    2 \n    2 \n    0 \n    173 \n    9.1 \n    4.1 \n    5.0 \n  \n  \n    2 \n    3 \n    1 \n    163 \n    5.8 \n    0.8 \n    5.0 \n  \n  \n    2 \n    4 \n    1 \n    525 \n    7.0 \n    2.0 \n    5.0 \n  \n  \n    3 \n    1 \n    0 \n    139 \n    6.5 \n    4.2 \n    2.3 \n  \n  \n    3 \n    2 \n    1 \n    173 \n    6.8 \n    4.4 \n    2.3 \n  \n  \n    3 \n    3 \n    1 \n    163 \n    2.8 \n    0.5 \n    2.3 \n  \n  \n    3 \n    4 \n    1 \n    525 \n    7.6 \n    1.0 \n    6.7"
  },
  {
    "objectID": "slides/slides5.html#two-way-fixed-effects",
    "href": "slides/slides5.html#two-way-fixed-effects",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Two-way Fixed Effects",
    "text": "Two-way Fixed Effects\n\ntwoway12 <- feols(actual_profit ~ report | firm + time,\n                  data = filter(rd_did3_panel, time != 3))\ntwoway13 <- feols(actual_profit ~ report | firm + time,\n                  data = filter(rd_did3_panel, time != 2))\ntwoway123 <- feols(actual_profit ~ report | firm + time,\n                  data = rd_did3_panel)"
  },
  {
    "objectID": "slides/slides5.html#separate-2-by-2-effects-are-larger-than-the-total-sample-effect",
    "href": "slides/slides5.html#separate-2-by-2-effects-are-larger-than-the-total-sample-effect",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Separate 2 by 2 effects are larger than the total sample effect",
    "text": "Separate 2 by 2 effects are larger than the total sample effect\n\nmsummary(list(\"time 1 and 2\" = twoway12, \"time 1 and 3\" = twoway13,\n              \"time 1, 2 and 3\" = twoway123), gof_omit = gof_omit,\n         stars = c(\"*\" = .1, \"**\" = .05, \"***\" = .01))\n\n\n\n \n  \n      \n     time 1 and 2 \n     time 1 and 3 \n     time 1, 2 and 3 \n  \n \n\n  \n    report \n    5.964*** \n    4.327*** \n    4.622*** \n  \n  \n     \n    (0.502) \n    (0.685) \n    (0.407) \n  \n  \n    Num.Obs. \n    2000 \n    2000 \n    3000 \n  \n  \n    R2 \n    0.589 \n    0.569 \n    0.442 \n  \n  \n    R2 Within \n    0.130 \n    0.039 \n    0.061 \n  \n  \n    RMSE \n    3.57 \n    3.73 \n    4.19 \n  \n  \n    Std.Errors \n    by: firm \n    by: firm \n    by: firm \n  \n  \n    FE: firm \n    X \n    X \n    X \n  \n  \n    FE: time \n    X \n    X \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01\n\n\n\n\n\nThis is not what I would expect. Why would the full sample lead to a smaller effect than all the subsamples?"
  },
  {
    "objectID": "slides/slides5.html#problem-statement",
    "href": "slides/slides5.html#problem-statement",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Problem Statement",
    "text": "Problem Statement\n\nFinally, when research settings combine staggered timing of treatment effects and treatment effect heterogeneity across firms or over time, staggered DiD estimates are likely to be biased. In fact, these estimates can produce the wrong sign altogether compared to the true average treatment effects."
  },
  {
    "objectID": "slides/slides5.html#solution",
    "href": "slides/slides5.html#solution",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Solution",
    "text": "Solution\n\nWhile the literature has not settled on a standard, the proposed solutions all deal with the biases arising from the “bad comparisons” problem inherent in TWFE DiD regressions by modifying the set of effective comparison units in the treatment effect estimation process. For example, each alternative estimator ensures that firms receiving treatment are not compared to those that previously received it.\n\n\nAgain, the solution to all our problems is to make sure that we make the right comparison."
  },
  {
    "objectID": "slides/slides5.html#simulation-setup---the-true-average-treatment-effect-of-three-groups",
    "href": "slides/slides5.html#simulation-setup---the-true-average-treatment-effect-of-three-groups",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Simulation Setup - The True Average Treatment Effect of Three Groups",
    "text": "Simulation Setup - The True Average Treatment Effect of Three Groups\n\n\nIt’s clear that the average treatment effect should be positive. It’s positive for every group."
  },
  {
    "objectID": "slides/slides5.html#the-estimated-effect-by-twoway-fixed-effects-of-500-simulations",
    "href": "slides/slides5.html#the-estimated-effect-by-twoway-fixed-effects-of-500-simulations",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "The Estimated Effect by Twoway Fixed Effects of 500 Simulations",
    "text": "The Estimated Effect by Twoway Fixed Effects of 500 Simulations"
  },
  {
    "objectID": "slides/slides5.html#the-sun2021-solution---restrict-the-sample",
    "href": "slides/slides5.html#the-sun2021-solution---restrict-the-sample",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "The Sun and Abraham (2021) Solution - Restrict The Sample",
    "text": "The Sun and Abraham (2021) Solution - Restrict The Sample"
  },
  {
    "objectID": "slides/slides5.html#the-estimated-effect-with-the-sun-and-abraham-solution",
    "href": "slides/slides5.html#the-estimated-effect-with-the-sun-and-abraham-solution",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "The Estimated Effect with the Sun and Abraham Solution",
    "text": "The Estimated Effect with the Sun and Abraham Solution"
  },
  {
    "objectID": "slides/slides5.html#sun-and-abraham-in-practice",
    "href": "slides/slides5.html#sun-and-abraham-in-practice",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Sun and Abraham in Practice",
    "text": "Sun and Abraham in Practice\n\nsa_new <- readRDS(here(\"data\", \"sa_new.RDS\"))\nsa_fe <- feols(roa ~ 1 + sunab(treatment_group, year) | firm + year,\n               cluster = \"state\", data = sa_new)\nsa_fe_att <- summary(sa_fe, agg = \"ATT\")\nsa_fe_group <- summary(sa_fe, agg = \"cohort\")\n\n\ntreatment_group: first year of treatment\nyear: calendar year\n\n\nnames(sa_fe$coefficients)\n\n [1] \"year::-18:cohort::1998\" \"year::-17:cohort::1998\" \"year::-16:cohort::1998\"\n [4] \"year::-15:cohort::1998\" \"year::-14:cohort::1998\" \"year::-13:cohort::1998\"\n [7] \"year::-12:cohort::1998\" \"year::-11:cohort::1998\" \"year::-10:cohort::1998\"\n[10] \"year::-9:cohort::1989\"  \"year::-9:cohort::1998\"  \"year::-8:cohort::1989\" \n[13] \"year::-8:cohort::1998\"  \"year::-7:cohort::1989\"  \"year::-7:cohort::1998\" \n[16] \"year::-6:cohort::1989\"  \"year::-6:cohort::1998\"  \"year::-5:cohort::1989\" \n[19] \"year::-5:cohort::1998\"  \"year::-4:cohort::1989\"  \"year::-4:cohort::1998\" \n[22] \"year::-3:cohort::1989\"  \"year::-3:cohort::1998\"  \"year::-2:cohort::1989\" \n[25] \"year::-2:cohort::1998\"  \"year::0:cohort::1989\"   \"year::0:cohort::1998\"  \n[28] \"year::1:cohort::1989\"   \"year::1:cohort::1998\"   \"year::2:cohort::1989\"  \n[31] \"year::2:cohort::1998\"   \"year::3:cohort::1989\"   \"year::3:cohort::1998\"  \n[34] \"year::4:cohort::1989\"   \"year::4:cohort::1998\"   \"year::5:cohort::1989\"  \n[37] \"year::5:cohort::1998\""
  },
  {
    "objectID": "slides/slides5.html#sun-and-abraham---relative-year",
    "href": "slides/slides5.html#sun-and-abraham---relative-year",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Sun and Abraham - Relative Year",
    "text": "Sun and Abraham - Relative Year\n\nmsummary(sa_fe, gof_omit = gof_omit, stars = stars, statistic = NULL,\n         estimate = \"{estimate} ({std.error}) {stars}\", coef_omit = \"-1\")\n\n\n\n \n  \n      \n     (1) \n  \n \n\n  \n    year = -9 \n    −0.003 (0.006) \n  \n  \n    year = -8 \n    0.001 (0.005) \n  \n  \n    year = -7 \n    −0.001 (0.006) \n  \n  \n    year = -6 \n    −0.002 (0.005) \n  \n  \n    year = -5 \n    0.005 (0.005) \n  \n  \n    year = -4 \n    0.003 (0.005) \n  \n  \n    year = -3 \n    0.004 (0.004) \n  \n  \n    year = -2 \n    0.010 (0.006) \n  \n  \n    year = 0 \n    0.011 (0.005) * \n  \n  \n    year = 1 \n    0.025 (0.006) *** \n  \n  \n    year = 2 \n    0.042 (0.006) *** \n  \n  \n    year = 3 \n    0.055 (0.005) *** \n  \n  \n    year = 4 \n    0.062 (0.005) *** \n  \n  \n    year = 5 \n    0.082 (0.006) *** \n  \n  \n    Num.Obs. \n    119996 \n  \n  \n    R2 \n    0.727 \n  \n  \n    R2 Within \n    0.005 \n  \n  \n    RMSE \n    0.17 \n  \n  \n    Std.Errors \n    by: state \n  \n  \n    FE: firm \n    X \n  \n  \n    FE: year \n    X"
  },
  {
    "objectID": "slides/slides5.html#sun-and-abraham---relative-year-1",
    "href": "slides/slides5.html#sun-and-abraham---relative-year-1",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Sun and Abraham - Relative Year",
    "text": "Sun and Abraham - Relative Year\n\niplot(sa_fe)"
  },
  {
    "objectID": "slides/slides5.html#sun-and-abraham---att",
    "href": "slides/slides5.html#sun-and-abraham---att",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Sun and Abraham - ATT",
    "text": "Sun and Abraham - ATT\n\nmsummary(sa_fe_att, gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n     (1) \n  \n \n\n  \n    ATT \n    0.046*** \n  \n  \n     \n    (0.009) \n  \n  \n    Num.Obs. \n    119996 \n  \n  \n    R2 \n    0.727 \n  \n  \n    R2 Within \n    0.005 \n  \n  \n    RMSE \n    0.17 \n  \n  \n    Std.Errors \n    by: state \n  \n  \n    FE: firm \n    X \n  \n  \n    FE: year \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides5.html#sun-and-abraham---cohort-effects",
    "href": "slides/slides5.html#sun-and-abraham---cohort-effects",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Sun and Abraham - Cohort Effects",
    "text": "Sun and Abraham - Cohort Effects\n\nmsummary(sa_fe_group, gof_omit = gof_omit, stars = stars)\n\n\n\n \n  \n      \n     (1) \n  \n \n\n  \n    cohort = 1989 \n    0.058*** \n  \n  \n     \n    (0.006) \n  \n  \n    cohort = 1998 \n    0.034*** \n  \n  \n     \n    (0.005) \n  \n  \n    Num.Obs. \n    119996 \n  \n  \n    R2 \n    0.727 \n  \n  \n    R2 Within \n    0.005 \n  \n  \n    RMSE \n    0.17 \n  \n  \n    Std.Errors \n    by: state \n  \n  \n    FE: firm \n    X \n  \n  \n    FE: year \n    X \n  \n\n\n * p < 0.1, ** p < 0.05, *** p < 0.01"
  },
  {
    "objectID": "slides/slides5.html#take-away-lessons",
    "href": "slides/slides5.html#take-away-lessons",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Take-away Lessons",
    "text": "Take-away Lessons\n\n\n\n\n\n\nNote\n\n\n\nSimulations are good!\nEverything is a regression (Ok, not really)\nNot all the data should go in the regression"
  },
  {
    "objectID": "slides/slides5.html#abadie2017",
    "href": "slides/slides5.html#abadie2017",
    "title": "Research Design 2: Event Studies and Difference-in-Difference",
    "section": "Abadie et al. (2017)",
    "text": "Abadie et al. (2017)\n\n\n\n\n\n\nNote\n\n\nWhat is the level of the treatment variable? What is the comparison?\n\n\n\n\nMixed race or same-sex race\nState legislation\nCountry legislation\nFirm corporate governance changes"
  },
  {
    "objectID": "freaky_friday/index.html",
    "href": "freaky_friday/index.html",
    "title": "Research Design",
    "section": "",
    "text": "This website is an attempt to replicate the main results in Dellavigna and Pollet (2009) from scratch. The paper is a good example because (1) it has an explicit theoretical model, (2) provides excellent descriptions on how the different measures are constructed, (3) uses the canonical finance design, an event study. I will focus most of my attention on (2) and (3) but (1) is important because it provides guidance to readers of the paper why the measures and the design is important.\nThe basic argument of the paper is that firms will bury earnings announcements on Fridays if the earnings are bad because the market pays less attention to news on Fridays."
  },
  {
    "objectID": "freaky_friday/index.html#the-unexpected-component-of-earnings",
    "href": "freaky_friday/index.html#the-unexpected-component-of-earnings",
    "title": "Research Design",
    "section": "The Unexpected Component of Earnings",
    "text": "The Unexpected Component of Earnings\n\\[ s_{t,k} = \\frac{e_{t,k} - \\hat{e}_{t,k}}{P_{t,k}} \\]\nIn this equation, \\(s_{t,k}\\) is the surprise (i.e. the unexpected component) in earnings of company \\(k\\) at time \\(t\\). It is calculated by the actual earnings per share, \\(e_{t,k}\\), minus the median expected earnings by analysts, \\(\\hat{e}_{t,k}\\), divided by the price of the stock 5 days before the earnings release, \\(P_{t,k}\\). You will see over and over that empirical researchers are wary that the day(s) just before an announcement might be special, i.e. the news might have already leaked out, for good and less good reasons. So, instead of using the price the day before the earnings release, the paper picks a couple of days earlier 2.\nThe most important part is that we try to filter out all the information in the earnings announcement that is already known to the market by subtracting the earnings estimates of analysts. The implicit assumption is that these earnings estimates are a good measure of the market’s information on the company just before the earnings are announced."
  },
  {
    "objectID": "freaky_friday/index.html#the-market-reaction",
    "href": "freaky_friday/index.html#the-market-reaction",
    "title": "Research Design",
    "section": "The Market Reaction",
    "text": "The Market Reaction\nThe market reaction is calculated as the abnormal return from day \\(h\\) to day \\(H\\). 3\n\\[ R_{t,k}^{(h, H)} = [\\Pi_{j=h}^H (1 + R_{j,k})] - 1\n- \\hat{\\beta}_{t,k} [\\Pi_{j=h}^H (1 + R_{j,m}) - 1]\\]\nThis looks complicated but it is quite simple. The first part is the raw return of the stock over the period that we are interested in 4. The second part is the return of the market times the sensitivity of the stock to the market. The latter, \\(\\hat{\\beta}_{t,k}\\) is estimated with data from before the announcement. The goal of this approach is to filter out other reasons that the stock price might go up or down because of general economic or financial events that affect the stock market as a whole.\nSpecifically, we estimate the following regression model with data from days, \\(u\\), with \\(u\\) between 46 and 300 days before the earnings announcements. This is a regression of the market return on the firm return.\n\\[ R_{u,k} = \\alpha_{t,k} + \\beta_{t,k} R_{u,m}\\]\nAgain, we are using data from long before the earnings announcement so that our estimate is not contaminated by the earnings announcement 5.\nThere are lot of different approaches in the literature to estimate these abnormal returns but they all have the same flavour of trying to filter out other reasons why the stock price might be moving. In a pure regression framework, we would include additional variables as control variables. Constructing variables like the abnormal returns and the earnings surprise like this serves exactly the same function. There are good reasons to use the approach of first constructing the measures as precise as possible in an event study design like this but there are some problem with applying this same logic in different research designs Chen, Hribar, and Melessa (n.d.)."
  },
  {
    "objectID": "freaky_friday/download_linking.html",
    "href": "freaky_friday/download_linking.html",
    "title": "WRDS linking data",
    "section": "",
    "text": "I use three packages on this page and two of them require some more explanation. The here package helps with managing the different files in this larger project. I can refer to different files relative to the root folder all the files are in. The only thing that I need to do is to say where this file is compared to the root folder with the i_am function. The second package is the RPostgres package that helps make a connection with the WRDS data sources."
  },
  {
    "objectID": "freaky_friday/download_linking.html#ibes",
    "href": "freaky_friday/download_linking.html#ibes",
    "title": "WRDS linking data",
    "section": "I/B/E/S",
    "text": "I/B/E/S\nThe SQL code instructs the WRDS data base to get the variables ticker, cusip (another identifier), cname (company name), and sdates (the start date for this ticker) from the ibes.idsum (IBES ID summary) database of WRDS. In this paper, we only want U.S. firms.\n\nSELECT ticker, cusip, cname, sdates\nFROM ibes.idsum\nWHERE usfirm = 1\n\nWith some R code, we clean the data and save it as a file in the data > wrds folder in our main folder.\n\nibes_id <- as_tibble(ibes_query) %>%\n  rename_all(tolower)\nsaveRDS(ibes_id, here(\"data\", \"wrds\", \"ibes_id.RDS\"))"
  },
  {
    "objectID": "freaky_friday/download_linking.html#crsp",
    "href": "freaky_friday/download_linking.html#crsp",
    "title": "WRDS linking data",
    "section": "CRSP",
    "text": "CRSP\nFrom the CRSP data, we get the permno and ncusip identifier where ncusip stands for the same cusip identifier as mentioned above. We also have the company name, start date, and end date.\n\nSELECT permno, ncusip, comnam, st_date, end_date\nFROM crsp.stocknames\n\n\ncrsp_id <- as_tibble(crsp_query) %>%\n  rename_all(tolower)\nsaveRDS(crsp_id, here(\"data\", \"wrds\", \"crsp_id.RDS\"))"
  },
  {
    "objectID": "freaky_friday/download_linking.html#compustat-with-ibes",
    "href": "freaky_friday/download_linking.html#compustat-with-ibes",
    "title": "WRDS linking data",
    "section": "Compustat with I/B/E/S",
    "text": "Compustat with I/B/E/S\nFrom Compustat we use the security file which has all the financial securities (and their identifiers) that are linked to the firms in Compustat. We select all the variables from that dataset. We only select the ones where the ibes ticker is available so that we can match via the ticker in the I/B/E/S files.\n\nSELECT *\nFROM comp.security\nWHERE ibtic IS NOT NULL\n\n\ncompu_security <- as_tibble(compu_security_query) %>%\n  rename_all(tolower)\nsaveRDS(compu_security, here(\"data\", \"wrds\", \"compu_security.RDS\"))"
  },
  {
    "objectID": "freaky_friday/download_linking.html#compustat-with-crsp",
    "href": "freaky_friday/download_linking.html#compustat-with-crsp",
    "title": "WRDS linking data",
    "section": "Compustat with CRSP",
    "text": "Compustat with CRSP\nFinally, we get the linking file in compustat. According to the documentation, not all the links are reliable and they advice to use the linktype variable and the usedflag variable to filter only the links that are most reliable. I have implemented the rules that follow best practice according to this tutorial (https://wrds-www.wharton.upenn.edu/pages/wrds-research/applications/linking-databases/linking-crsp-and-compustat/)\n\nSELECT gvkey, linktype, usedflag, liid, lpermno, linkdt, linkenddt\nFROM crsp.Ccmxpf_linktable\n\n\ncrsp_compu <- as_tibble(compu_query) %>%\n  rename_all(tolower) %>%\n  select(gvkey, linktype, usedflag, iid = liid, permno = lpermno, stdt = linkdt, enddt = linkenddt) %>%\n  filter(!is.na(permno), linktype %in% c(\"LU\", \"LC\"), usedflag == 1) %>%\n  select(gvkey, permno, stdt, enddt) %>%\n  distinct()\nsaveRDS(crsp_compu, here(\"data\", \"wrds\", \"crsp_compu.RDS\"))"
  },
  {
    "objectID": "freaky_friday/linking.html",
    "href": "freaky_friday/linking.html",
    "title": "Combining databases",
    "section": "",
    "text": "The packages are the same as before."
  },
  {
    "objectID": "freaky_friday/linking.html#linking-ibes",
    "href": "freaky_friday/linking.html#linking-ibes",
    "title": "Combining databases",
    "section": "Linking I/B/E/S",
    "text": "Linking I/B/E/S\n\nlinking_table %>%\n  select(gvkey, ticker) %>%\n  distinct() %>%\n  summarise(N = n(), .by = ticker) %>%\n  filter(N > 1)\n\n# A tibble: 0 × 2\n# … with 2 variables: ticker <chr>, N <int>\n\n\nThere are no tickers linked with multiple gvkeys. This means that left_join from I/B/E/S is the way to start the joining process. That way, there will be no duplicate matches from Compustat."
  },
  {
    "objectID": "freaky_friday/download_data.html",
    "href": "freaky_friday/download_data.html",
    "title": "Earnings announcements",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\ni_am(\"freaky_friday/download_data.qmd\")\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\nlibrary(RPostgres)\nlibrary(dtplyr)\nlinking_table <- readRDS(here(\"data\", \"freaky_friday\", \"linking_table.RDS\"))"
  },
  {
    "objectID": "freaky_friday/download_data.html#ibes",
    "href": "freaky_friday/download_data.html#ibes",
    "title": "Earnings announcements",
    "section": "I/B/E/S",
    "text": "I/B/E/S\nWe start with the earnings announcement data from I/B/E/S with the analyst estimates. According to the method section in Dellavigna and Pollet (2009), we need the data from the start of 1995 to the middle of 2006. We will want the analyst estimates for all the firms with a ticker in the master linking_table.\nI am going to use parameters that we can calculate or set in R and then pass them on to the SQL query. The details are explained in this blogpost by Irene Steves.\n\nbegin_date <- \"'1995-01-01'\"\nend_date <- \"'2006-07-01'\"\ntickers <- unique(linking_table$ticker)\ntickers_sql <- glue::glue_sql(\"{tickers*}\", .con = wrds)\n\nThe dates of the estimate and the actual earnings announcement will be critical to construct unexpected component of the earnings and to determine the exact event data, i.e. the date that (the unexpected component of) the earnings are announced. Thankfully, WRDS provides a description of the date variables. anndats is the first day that an analyst set their estimate for the earnings per share and the revdats is the last day that the analyst confirmed their estimate. We will use revdats as the defacto date that the analyst provided the estimate. anndats_act is the earnings announcement date. value is the estimated EPS by the analyst and actual is the actual EPS as announced by the firm. pdf is flag whether the EPS if for the primary share class or on a diluted basis. I included both and that is probably appropriate for this paper. fpi is the forecast period indicator if we set this to “6”, we get the earnings estimates that are done in the quarter before the earnings announcements. All these variables can be verified in the data descriptions on WRDS. As you can see, it’s quite important if you work with data that you have not collected yourself to read the data descriptions.\nIn the actual sql query you can see that the I use the parameters that I constructed before in R by adding an ? infront of the parameter name when using them.\n\nSELECT ticker, cusip, fpi, anndats, revdats, pdf, value, anndats_act, actual, analys\nFROM ibes.det_epsus\nWHERE anndats_act BETWEEN ?begin_date AND ?end_date\nAND actual IS NOT NULL\nAND fpi = '6'\nAND ticker IN (?tickers_sql)\n\nWe save the data with R. See the previous page for how to get the output of an sql query into R.\n\nann_ibes <- as_tibble(ibes_query) %>%\n  rename_all(tolower)\nsaveRDS(ann_ibes, here(\"data\", \"freaky_friday\", \"ann_ibes.RDS\"))\nglimpse(ann_ibes)\n\nRows: 1,046,677\nColumns: 10\n$ ticker      <chr> \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\"…\n$ cusip       <chr> \"0039241X\", \"0039241X\", \"0039241X\", \"0039241X\", \"0039241X\"…\n$ fpi         <chr> \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\"…\n$ anndats     <date> 2006-02-02, 2006-02-01, 2006-02-01, 2006-02-01, 2006-02-0…\n$ revdats     <date> 2006-02-20, 2006-02-06, 2006-02-06, 2006-02-06, 2006-02-0…\n$ pdf         <chr> \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\"…\n$ value       <dbl> -0.0523, -0.0785, -0.0800, -0.0785, -0.0960, -0.0800, -0.0…\n$ anndats_act <date> 2006-04-26, 2006-04-26, 2006-04-26, 2006-04-26, 2006-04-2…\n$ actual      <dbl> -0.0800, -0.0800, -0.0800, -0.0800, -0.0800, -0.0800, -0.0…\n$ analys      <dbl> 43594, 84303, 87125, 5469, 44775, 478, 43594, 87125, 71785…"
  },
  {
    "objectID": "freaky_friday/download_data.html#compustat",
    "href": "freaky_friday/download_data.html#compustat",
    "title": "Earnings announcements",
    "section": "Compustat",
    "text": "Compustat\nFollowing the paper, we will verify the earnings announcement date in I/B/E/S with the earnings announcement date in Compustat. Given the importance of finding the exact date for an event study, it is not surprising that Dellavigna and Pollet (2009) spent a lot of effort to make sure that they have the date right.\n\ngvkeys <- unique(linking_table$gvkey)\ngvkeys_sql <- glue::glue_sql(\"{gvkeys*}\", .con = wrds)\n\nrdq is the earnings announcement data in Compustat.\n\nSELECT cusip, rdq, gvkey\nFROM comp.fundq\nWHERE rdq BETWEEN ?begin_date AND ?end_date\nAND gvkey IN (?gvkeys_sql)\n\n\nann_compu <- as_tibble(compu_query) %>%\n  rename_all(tolower) %>%\n  mutate(cusip = str_sub(cusip, 1, 8))\nsaveRDS(ann_compu, here(\"data\", \"freaky_friday\", \"ann_compu.RDS\"))\nglimpse(ann_compu)\n\nRows: 328,000\nColumns: 3\n$ cusip <chr> \"00036110\", \"00036110\", \"00036110\", \"00036110\", \"00036110\", \"000…\n$ rdq   <date> 1995-03-15, 1995-07-06, 1995-09-13, 1995-12-12, 1996-03-14, 199…\n$ gvkey <chr> \"001004\", \"001004\", \"001004\", \"001004\", \"001004\", \"001004\", \"001…"
  },
  {
    "objectID": "freaky_friday/download_data.html#combine-announcements",
    "href": "freaky_friday/download_data.html#combine-announcements",
    "title": "Earnings announcements",
    "section": "Combine Announcements",
    "text": "Combine Announcements\nTo combine the two datasets, we will link them through a simplified version of the larger linking table. I will also enforce that the first 6 characters of cusip are the same. I don’t think it is strictly necessary to do that but it does gives us more confidence that the links are of higher quality. We need to match the I/B/E/S data and the Compustat data based on the firm and its earnings announcement date. However, if you read the paper (Dellavigna and Pollet 2009), you will notice that the reason why want to combine is because the date in both datasets does not always match. The paper gets around that by matching earnings announcements if the date is not more than 5 days apart in the two data sources. This is why I create anndat_begin and anndat_end to define the interval in which we want to match the data. Finally, we can calculate the actual event date as the minimum of the date in the I/B/E/S data and the Compustat data (Dellavigna and Pollet 2009) 1.\nYou can also see that I have two lines of commented code. In these lines, I read in the datasets again. This is not strictly necessary to make this file fully reproducible but it does make debugging the code easier. If I want to make some changes to the code I do not have to download the data again from WRDS. I can just use the one in the data folder.\n\n# ann_ibes <- readRDS(here(\"data\", \"freaky_friday\", \"ann_ibes.RDS\"))\n# ann_compu <- readRDS(here(\"data\", \"freaky_friday\", \"ann_compu.RDS\"))\nsimple_link <- linking_table %>%\n  select(ticker, gvkey, permno, cusip) %>%\n  mutate(cusip = str_sub(cusip, end = 6)) %>%\n  distinct()\nearn_ann <- ann_ibes %>% distinct(ticker, actual, pdf, cusip, anndats_act) %>%\n  mutate(cusip = str_sub(cusip, end = 6)) %>%\n  left_join(simple_link, by = join_by(ticker)) %>%\n  filter(!is.na(gvkey), !(cusip.x != cusip.y)) %>%\n  select(-starts_with(\"cusip\")) %>%\n  mutate(anndat_begin = anndats_act - 5, anndat_end = anndats_act + 5) %>%\n  left_join(ann_compu, by = join_by(gvkey == gvkey,\n                                    anndat_begin <= rdq,  anndat_end >= rdq)) %>%\n  filter(!is.na(rdq)) %>%\n  mutate(anndat = pmin(anndats_act, rdq)) %>%\n  select(-anndat_begin, -anndat_end)\n\nWarning in left_join(., simple_link, by = join_by(ticker)): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 125 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\nsaveRDS(earn_ann, here(\"data\", \"freaky_friday\", \"earn_ann.RDS\"))\nglimpse(earn_ann)\n\nRows: 154,540\nColumns: 9\n$ ticker      <chr> \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"AA0A\", \"AA0A\", …\n$ actual      <dbl> -0.0800, -0.0400, -0.1100, -0.1100, -0.0500, -0.0700, -0.1…\n$ pdf         <chr> \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\"…\n$ anndats_act <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-2…\n$ gvkey       <chr> \"001081\", \"001081\", \"001081\", \"001081\", \"001081\", \"001081\"…\n$ permno      <dbl> 10560, 10560, 10560, 10560, 10560, 10560, 10560, 10656, 10…\n$ cusip       <chr> \"00392410\", \"00392410\", \"00392410\", \"00392410\", \"00392410\"…\n$ rdq         <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-2…\n$ anndat      <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-2…\n\n\nearn_ann serves as a linking table to match different earnings announcements (as opposed to firms and their securities in linking_table)\n\n\n\nvariable\ndata source\ndescription\n\n\n\n\nticker\nI/B/E/S\nIdentifier\n\n\nanndats_act\nI/B/E/S\nActual Announcement Date\n\n\ngvkey\nCompustat\nIdentifier\n\n\npermno\nCRSP\nIdentifier\n\n\ncusip\n\nIdentifier of length 6,8 or 9\n\n\nrdq\nCompustat\nActual Announcement Date\n\n\nanndat\n\npmin(rdq, anndats_act)\n\n\n\nanndat is the validated way of calculating the announcement date. However, we need to keep the other dates around because we will need them to link back to the original databases.\nThe paper states that they have 154,051 earnings announcements (Dellavigna and Pollet 2009). We have 154540 earnings announcements."
  },
  {
    "objectID": "freaky_friday/download_stocks.html",
    "href": "freaky_friday/download_stocks.html",
    "title": "Stock price data",
    "section": "",
    "text": "On this page, we download the stock price data so that we can later calculate the abnormal return after the earnings announcements.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\nlibrary(RPostgres)\ni_am(\"freaky_friday/download_stocks.qmd\")\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\nearn_ann <- readRDS(here(\"data\", \"freaky_friday\", \"earn_ann.RDS\"))\n\n\nwrds <- dbConnect(Postgres(),\n                  host='wrds-pgdata.wharton.upenn.edu',\n                  port=9737,\n                  dbname='wrds',\n                  user='stimas',\n                  sslmode='require')\n\nThis section sets the sql parameters. The beginning date is 300 days before the first earnings announcement and the end date is 75 days after the last earnings announcement. Finally, I keep the permno identifiers because these are the only stocks we want the data from.\n\ncrsp_input <- earn_ann %>%\n  summarise(begin = min(anndat) - 300, end = max(anndat) + 75, .by = permno) %>%\n  glimpse()\n\nRows: 8,759\nColumns: 3\n$ permno <dbl> 10560, 10656, 88784, 10659, 84606, 88790, 29058, 87771, 88836, …\n$ begin  <date> 2003-12-26, 2002-07-12, 2001-01-17, 2001-11-09, 2001-07-03, 20…\n$ end    <date> 2006-07-10, 2006-07-19, 2006-07-18, 2006-05-23, 2006-07-09, 20…\n\nbegin_date <- min(crsp_input$begin)\nend_date <- max(crsp_input$end)\npermno_sql <- glue::glue_sql(\"{crsp_input$permno*}\", .con = wrds)\n\nI use the same syntax as before to call the WRDS databases as before with sql interspersed with the R parameters created in the previous code block. We get the daily volume, return, price, shares outstanding, cumulative factor to adjust price, and cumulative factor to adjust shares. The latter two are adjustment factors for stock splits and dividends which we probably will not need but if we do we have them.\nThis is by far the largest download from WRDS and this is why it has it’s own page. We do not want to rerun this more than strictly necessary.\n\nSELECT permno, date, vol, ret, prc, shrout, cfacpr, cfacshr\nFROM crsp_a_stock.dsf\nWHERE permno IN (?permno_sql)\nAND date BETWEEN ?begin_date AND ?end_date\n\n\nall_stocks <- as_tibble(crsp_query) %>%\n  rename_all(tolower)\nprint(all_stocks)\n\n# A tibble: 14,973,747 × 8\n   permno date          vol      ret   prc shrout cfacpr cfacshr\n    <dbl> <date>      <dbl>    <dbl> <dbl>  <dbl>  <dbl>   <dbl>\n 1  10002 1994-03-10    700 -0.00952 13      2999   1.5     1.5 \n 2  10010 1994-03-10  65220 -0.0161   7.62   9348   1.1     1.1 \n 3  10011 1994-03-10  31600  0.0179   7.12   5303   1       1   \n 4  10012 1994-03-10  46000 -0.0500   2.38  14581   1       1   \n 5  10019 1994-03-10   2100  0        8.75   5238   1.5     1.5 \n 6  10025 1994-03-10  16304 -0.00685 18.1    7329   1       1   \n 7  10026 1994-03-10  23525 -0.00680 18.2   10341   2       2   \n 8  10032 1994-03-10   4269  0       16.2    6456   4       4   \n 9  10035 1994-03-10 268078  0.0282  18.2   13029   1       1   \n10  10042 1994-03-10 103900  0        3.56  25318   0.25    0.25\n# … with 14,973,737 more rows\n\nsaveRDS(all_stocks, here(\"data\", \"freaky_friday\", \"all_stocks.RDS\"))\n\nOne important footnote is that the price is negative on days where there were no trades. This might be important going forward."
  },
  {
    "objectID": "freaky_friday/abnormal_returns.html",
    "href": "freaky_friday/abnormal_returns.html",
    "title": "Abnormal returns",
    "section": "",
    "text": "Setup\nThe lubridate package is the tidyverse package that helps with time related data. Dates are a specific class of variables and the package helps with managing date variables.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(here)\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\ni_am(\"freaky_friday/abnormal_returns.qmd\")\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\n\nIn order to predict the expected market return reaction to earnings, we will want to take into account the general market reaction. Dellavigna and Pollet (2009) only adjust for the overall market return. There are other adjustments possible for specific risk factors. The original factor model is the Fama-French 3 Factors model and the data is available via the Kenneth French data library.\nI have downloaded the data as a .csv file. The code reads the data in skipping 5 lines and reading the variables as numbers (double precision). We then need to transform the date variable to a date type with a function from the lubridate package. Finally, we need to scale the returns by 100 because they are expressed in percentages. For replicating the Dellavigna and Pollet (2009) paper, we only need the market return minus the risk free rate (mkt_rf) and the risk free rate (rf). If I read this paper correctly, we need to use the raw market return which is calculated as mkt.\n\nearn_ann <- readRDS(here(\"data\", \"freaky_friday\", \"earn_ann.RDS\"))\nanalyst <- readRDS(here(\"data\", \"freaky_friday\", \"analyst.RDS\"))\nall_stocks <- readRDS(here(\"data\", \"freaky_friday\", \"all_stocks.RDS\"))\nfamafrench <- read_csv(file = here(\"data\", \"F-F_Research_Data_Factors_daily.csv\"),\n                       col_names = c(\"date\", \"mkt_rf\", \"smb\", \"hml\", \"rf\"),\n                       skip = 5, col_type = \"ddddd\") %>%\n  mutate(date = ymd(date)) %>%\n  mutate_if(is.numeric, ~ . / 100) %>%\n  mutate(mkt = mkt_rf + rf) %>% \n  print()\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\n# A tibble: 25,400 × 6\n   date        mkt_rf     smb     hml      rf      mkt\n   <date>       <dbl>   <dbl>   <dbl>   <dbl>    <dbl>\n 1 1926-07-01  0.001  -0.0025 -0.0027 0.00009  0.00109\n 2 1926-07-02  0.0045 -0.0033 -0.0006 0.00009  0.00459\n 3 1926-07-06  0.0017  0.003  -0.0039 0.00009  0.00179\n 4 1926-07-07  0.0009 -0.0058  0.0002 0.00009  0.00099\n 5 1926-07-08  0.0021 -0.0038  0.0019 0.00009  0.00219\n 6 1926-07-09 -0.0071  0.0043  0.0057 0.00009 -0.00701\n 7 1926-07-10  0.0062 -0.0053 -0.001  0.00009  0.00629\n 8 1926-07-12  0.0004 -0.0003  0.0064 0.00009  0.00049\n 9 1926-07-13  0.0048 -0.0028 -0.002  0.00009  0.00489\n10 1926-07-14  0.0004  0.0007 -0.0043 0.00009  0.00049\n# … with 25,390 more rows\n\n\n\nshrout is shares outstanding in 1000\nmarket_value is in million USD\n\n\n\nAbnormal returns\nRemember that we are interested in predicting the counterfactual of what the returns would have been if there were no earnings announcement. We use the following prediction model:\n\\[ R_{u,k} = \\alpha_{t,k} + \\beta_{t,k} R_{u,m}\\]\nThat means that we need to estimate \\(\\alpha\\) and \\(\\beta\\) for each announcement based on the market return and firm return from 300 days before the earnings announcement to 46 days before the earnings announcements (Dellavigna and Pollet 2009). This is a lot of computations!\nI played around with a lot of different implementations and finally settled on a completely tidyverse style implementation as the fastest on my machine. I did not include the other implementations in this document but I will show how you can test the timing of your code with the microbenchmark package.\nThe first thing we need to do is to write the code as a function that we can call as many times as we need. 1 I call this function create_coefs. The input of the function is n, the number of earnings announcements we want to run the code for. The output is a tibble with the coefficients \\(\\alpha\\) and \\(\\beta\\) for each permno and anndat combination.\nThe actual function takes the earnings announcement data and keeps the unique permno and anndat combinations. Next, the start and end data for the return data is calculated based on the earnings announcement date. Next, we merge the return data and the Fama-French data and delete the missing or infinite observations for the return.\n\n\n\n\n\n\nNote\n\n\n\nAt this point, you can see the flexibility of my approach to keep the data sets separate until we need to join them. The earnings announcement data is one row per earnings announcement date per firm. The stock data has one observation per firm per day. The Fama-French data has one observation per day. Because these data have a different level of analysis, I have kept them separate until the point that we need to analyse the data. If I have to update one of the datasets, I do not necessarily have to update all the other ones. I would strongly encourage you to do the same thing where you keep different parts of the data cleaning separate for as long as possible. This will make your code flexible and easy to adapt.\n\n\nThe next two steps are the most advanced ones. First, remark that we have multiple rows for each earnings announcement. We use the summarise function to put all the returns in a vector y and we make a matrix X with all 1’s in the first column and the mkt. Remark that we are wrapping y and X in a list so that we effectively make y and X list columns in our tibble. The tidyverse lets us put almost anything in a dataset as long as we wrap it in a list. Finally, we summarise the y and X not just for the whole dataset but for each combination of permno and anndat. Thus, we end up with a dataset with a row for each earnings announcement with the returns we want to predict (y) from before the earnings announcement and the market returns from the same time period (X).\nIn the second step, we will run the regression for each row to estimate \\(\\alpha\\) and \\(\\beta\\). We do use a lightweight version of lm called lm.fit to speed up the estimation. lm.fit calculates less statistics like the standard errors that we need to calculate the p-values. Because ultimately, we need to this for 150,000 rows lm.fit will save considerable time compared to lm. lm.fit works slightly different in that now regression equation is specified. You need to give the predictors as the first argument and the outcome variable as the second argument. This is the reason why we formed the y and X variable in the previous step. We just need the coefficients form the fit object and we can use the coef function to extract them.\nFinally, we want to apply this lm.fit function to every row (i.e. for every earnings announcement). We use the map-family to apply a function to every element of a column. The pmap function specifically let us apply a function to multiple columns if we wrap them in a list. So, pmap takes the list of columns X and y and applies (~) the function lm.fit to the first (..1) and second (..2) element of that list. At the end, we extract the coefficients.\nThe microbenchmark function allows us to test the time it takes to run this function for 100, 1000, and 10000 earnings announcements. The computations are done 10 times for each call to get an average/median estimate 2. The surprising thing to me was that the function scales very well. The average time per announcement goes down with more announcements.\n\ncreate_coefs <- function(n = 6){\n  earn_ann %>% head(n = n) %>%\n    distinct(permno, anndat) %>%\n    mutate(start = anndat - 300, end = anndat - 46) %>%\n    left_join(select(all_stocks, permno, date, ret),\n              by = join_by(permno == permno, start <= date, end >= date)) %>%\n    left_join(select(famafrench, mkt, rf, date),\n              by = join_by(date == date)) %>%\n    filter(!is.na(ret), !is.infinite(ret)) %>%\n    summarise(y = list(cbind(ret)), X = list(cbind(alpha = 1, beta = mkt)),\n              .by = c(permno, anndat)) %>%\n    mutate(coefs = pmap(list(X, y), ~ lm.fit(..1, ..2) %>% coef()),\n           .by = c(permno, anndat)) %>%\n    select(-y, -X)\n}\n\nmicrobenchmark::microbenchmark(\n                  create_coefs(100),\n                  create_coefs(1000),\n                  create_coefs(10000),\n                  times = 10)\n\nUnit: seconds\n                expr      min       lq     mean   median       uq      max\n   create_coefs(100) 2.486352 2.613228 2.743136 2.723494 2.905908 2.965565\n  create_coefs(1000) 2.843033 2.874123 3.081922 2.987862 3.166263 3.740572\n create_coefs(10000) 5.265346 5.526715 5.799489 5.771547 5.859633 7.020166\n neval\n    10\n    10\n    10\n\n\nNext, we calculate the coefficients for all announcements and save them in the results object. Next, we need to calculate the abnormal returns based on the following formula in Dellavigna and Pollet (2009).\n\\[ R_{t,k}^{(h, H)} = [\\Pi_{j=h}^H (1 + R_{j,k})] - 1\n- \\hat{\\beta}_{t,k} [\\Pi_{j=h}^H (1 + R_{j,m}) - 1]\\]\nIn the results, the coef column is a list column where each row has two elements: alpha and beta. The unnest_wider function splits the list columns in two columns alpha and beta. Next we create the date 75 days after the announcement because that is the longest time frame the paper is interested (Dellavigna and Pollet 2009). Just like before, we add the relevant stock price data and Fama-French data. Our dataset now has a row for each day 0 to 75 days after the announcement date. Dellavigna and Pollet (2009) are interested in the short term abnormal return on the day of the announcement and the day after (0-1 days) and the long term abnormal return (2-75 days). I create the time_frame variable to denote whether a day should be counted in the short or long cumulative abnormal return. As an intermediate step, I calculate the products of the (market) returns + 1 (see the equation) by announcement and time frame (and beta because we need it for further calculations).\nFinally, I use the pivot_wider function to transform the dataset from the long format to a wider format. Specifically, each announcement has two rows one for the short term car and one for the long term car. The transformation will create a new dataset where every row has a different announcement with a car_long and a car_short. We do that by taking the values_from the car variable and the name for the column from the time_frame variable.\n\nN <- nrow(earn_ann)\nresults <- create_coefs(N)\n\nabnormal <- results %>%\n  unnest_wider(coefs) %>%\n  mutate(date75 = anndat + 75) %>%\n  left_join(select(all_stocks, permno, date, ret),\n            by = join_by(permno == permno,\n                         date75 >= date, anndat <= date)) %>%\n  left_join(select(famafrench,  mkt, rf, date),\n            by = join_by(date == date)) %>%\n  mutate(time_frame = if_else(date - anndat <= 1, \"short\", \"long\")) %>%\n  summarise(raw = prod(1 + ret), mkt = prod(1 + mkt),\n            .by = c(permno, anndat, time_frame, beta)) %>%\n  mutate(car = raw - 1 - beta * (mkt - 1)) %>%\n  select(-beta, -raw, -mkt) %>%\n  filter(!is.na(car)) %>%\n  pivot_wider(values_from = car, names_from = time_frame,\n              names_prefix = \"car_\")\nglimpse(abnormal)\n\nRows: 128,114\nColumns: 4\n$ permno    <dbl> 10560, 10560, 10560, 10560, 10560, 10560, 10560, 10656, 1065…\n$ anndat    <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-27,…\n$ car_short <dbl> -0.053110221, 0.097290996, 0.036461999, -0.063605082, -0.004…\n$ car_long  <dbl> -0.33518052, 0.01028760, -0.20959886, 0.05661849, -0.1836808…\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pivot_wider and pivot_longer functions are really, really useful when you are working with poorly structured data. As a rule of thumb when you clean and summarise the data, you will want the data to be in a long format where each row is its own distinct unit of analysis (Wickham 2014). For instance, in this code we had a row for each return day after the announcement for each announcement. The big advantage is that we can easily, with code, change the groups of data that we want to summarise, mutate, or filter. If we want to change what the short time frame means, we can just change that one line of code (e.g. to data - anndat <= 5). The wider format is more useful to present the data. That is why I use it more often at the end of an analysis.\n\n\n\n\nPutting it all together\nFinally, we want to put all the data together. You can see that we only merge all the data at the end. This is good practice. I would advise to not even try to build up a complete dataset by starting with for instance the I/B/E/S data and than to gradually add the variables that you need. This is a very error prone process and it is hard to make changes without redoing the whole data cleaning process.\nFirst, we need more stock price data and the market value from the CRSP data. We collect this in the clean_prices dataset. Remark that I remove the data where the price is negative because that means that there were no trades that day. Dellavigna and Pollet (2009) require the price and market value 5 days before the earnings announcement. My guess is that they are trying to avoid any effects of information leaking out into the market before the earnings announcement. I then merge the earnings announcement data with the analyst estimates data, the abnormal return data and the price and market value data. Finally, I calculate the earnings surprise as the difference between the actual and the median predicted earnings per share divided by the price per share to get the earnings surprise per dollar of market value.\n\nclean_prices <- all_stocks %>%\n  filter(prc > 0) %>%\n  select(permno, date, prc, shrout) %>%\n  mutate(market_value = prc * shrout) %>%\n  select(-shrout) %>%\n  print()\n\n# A tibble: 14,339,244 × 4\n   permno date         prc market_value\n    <dbl> <date>     <dbl>        <dbl>\n 1  10002 1994-03-10 13          38987 \n 2  10010 1994-03-10  7.62       71278.\n 3  10011 1994-03-10  7.12       37784.\n 4  10012 1994-03-10  2.38       34630.\n 5  10019 1994-03-10  8.75       45832.\n 6  10025 1994-03-10 18.1       132838.\n 7  10026 1994-03-10 18.2       188723.\n 8  10032 1994-03-10 16.2       104910 \n 9  10035 1994-03-10 18.2       237779.\n10  10042 1994-03-10  3.56       90195.\n# … with 14,339,234 more rows\n\nsurprise <- earn_ann %>%\n  left_join(analyst,\n            by = join_by(ticker, anndat, actual, pdf)) %>%\n  left_join(abnormal,\n            by = join_by(permno, anndat)) %>%\n  mutate(date_minus5 = anndat - 5) %>%\n  left_join(clean_prices,\n            by = join_by(permno, closest(date_minus5 >= date))) %>%\n  mutate(surprise = (actual - median) / prc) \nglimpse(surprise)\n\nRows: 154,540\nColumns: 20\n$ ticker       <chr> \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"AA0A\", \"AA0A\",…\n$ actual       <dbl> -0.0800, -0.0400, -0.1100, -0.1100, -0.0500, -0.0700, -0.…\n$ pdf          <chr> \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D…\n$ anndats_act  <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ gvkey        <chr> \"001081\", \"001081\", \"001081\", \"001081\", \"001081\", \"001081…\n$ permno       <dbl> 10560, 10560, 10560, 10560, 10560, 10560, 10560, 10656, 1…\n$ cusip        <chr> \"00392410\", \"00392410\", \"00392410\", \"00392410\", \"00392410…\n$ rdq          <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ anndat       <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ N            <int> 4, 1, 2, 3, 2, 4, 5, 1, NA, 1, 1, NA, NA, NA, 1, 2, 1, NA…\n$ median       <dbl> -0.07425, -0.09000, -0.08965, -0.05740, -0.03700, -0.1061…\n$ mean         <dbl> -0.0726250, -0.0900000, -0.0896500, -0.0680000, -0.037000…\n$ mean_days    <dbl> 11.500000, 21.000000, 8.000000, 6.666667, 13.500000, 7.00…\n$ car_short    <dbl> -0.053110221, 0.097290996, 0.036461999, -0.063605082, -0.…\n$ car_long     <dbl> -0.33518052, 0.01028760, -0.20959886, 0.05661849, -0.1836…\n$ date_minus5  <date> 2006-04-21, 2004-10-16, 2005-01-21, 2005-04-22, 2005-07-…\n$ date         <date> 2006-04-21, 2004-10-15, 2005-01-21, 2005-04-22, 2005-07-…\n$ prc          <dbl> 4.280, 5.630, 5.890, 4.530, 5.000, 3.260, 4.020, 16.750, …\n$ market_value <dbl> 1883949.1, 2478185.3, 2592630.7, 1993992.8, 2200875.0, 14…\n$ surprise     <dbl> -0.0013434579, 0.0088809945, -0.0034550086, -0.0116114785…\n\n\n\n\nData Cleaning\nFinally, I apply the data cleaning rules from Dellavigna and Pollet (2009). I also include the a print statement so that we can track how many observations are removed after each data cleaning step. The following rules are applied:\n\nRemove the observations where surprise is missing.\nRemove the observations where the median or actual estimate is larger than the price.\nRemove penny stocks which I arbitrarily and after some googling decide to be stocks with a price lower than $2 per stock.\nRemove the observations with earnings announcement on Saturday and Sunday.\nI remove the observations with a car in the top and bottom .05% of observations.\n\n\nwinsorise <- 5/10000\nmain <- surprise %>%\n  filter(!is.na(surprise)) %>% print(n = 0) %>%\n  filter(abs(median) < prc, abs(actual) < prc) %>% print(n = 0) %>%\n  filter(prc > 2) %>% print(n = 0) %>%\n  mutate(weekday = wday(anndat, label = TRUE)) %>%\n  filter(! weekday %in% c(\"Sat\", \"Sun\")) %>% print(n = 0) %>%\n  filter(percent_rank(car_long) >= winsorise,\n         percent_rank(car_long) <= 1 - winsorise,\n         percent_rank(car_short) >= winsorise,\n         percent_rank(car_short) <= 1 - winsorise) %>%\n  print()\n\n# A tibble: 137,403 × 20\n# … with 137,403 more rows, and 20 variables: ticker <chr>, actual <dbl>,\n#   pdf <chr>, anndats_act <date>, gvkey <chr>, permno <dbl>, cusip <chr>,\n#   rdq <date>, anndat <date>, N <int>, median <dbl>, mean <dbl>,\n#   mean_days <dbl>, car_short <dbl>, car_long <dbl>, date_minus5 <date>,\n#   date <date>, prc <dbl>, market_value <dbl>, surprise <dbl>\n# A tibble: 136,029 × 20\n# … with 136,029 more rows, and 20 variables: ticker <chr>, actual <dbl>,\n#   pdf <chr>, anndats_act <date>, gvkey <chr>, permno <dbl>, cusip <chr>,\n#   rdq <date>, anndat <date>, N <int>, median <dbl>, mean <dbl>,\n#   mean_days <dbl>, car_short <dbl>, car_long <dbl>, date_minus5 <date>,\n#   date <date>, prc <dbl>, market_value <dbl>, surprise <dbl>\n# A tibble: 133,703 × 20\n# … with 133,703 more rows, and 20 variables: ticker <chr>, actual <dbl>,\n#   pdf <chr>, anndats_act <date>, gvkey <chr>, permno <dbl>, cusip <chr>,\n#   rdq <date>, anndat <date>, N <int>, median <dbl>, mean <dbl>,\n#   mean_days <dbl>, car_short <dbl>, car_long <dbl>, date_minus5 <date>,\n#   date <date>, prc <dbl>, market_value <dbl>, surprise <dbl>\n# A tibble: 133,611 × 21\n# … with 133,611 more rows, and 21 variables: ticker <chr>, actual <dbl>,\n#   pdf <chr>, anndats_act <date>, gvkey <chr>, permno <dbl>, cusip <chr>,\n#   rdq <date>, anndat <date>, N <int>, median <dbl>, mean <dbl>,\n#   mean_days <dbl>, car_short <dbl>, car_long <dbl>, date_minus5 <date>,\n#   date <date>, prc <dbl>, market_value <dbl>, surprise <dbl>, weekday <ord>\n# A tibble: 130,807 × 21\n   ticker actual pdf   anndats_…¹ gvkey permno cusip rdq        anndat         N\n   <chr>   <dbl> <chr> <date>     <chr>  <dbl> <chr> <date>     <date>     <int>\n 1 A2     -0.08  D     2006-04-26 0010…  10560 0039… 2006-04-26 2006-04-26     4\n 2 A2     -0.04  D     2004-10-21 0010…  10560 0039… 2004-10-21 2004-10-21     1\n 3 A2     -0.11  D     2005-01-26 0010…  10560 0039… 2005-01-26 2005-01-26     2\n 4 A2     -0.11  D     2005-04-27 0010…  10560 0039… 2005-04-27 2005-04-27     3\n 5 A2     -0.05  D     2005-07-27 0010…  10560 0039… 2005-07-27 2005-07-27     2\n 6 A2     -0.07  D     2005-10-26 0010…  10560 0039… 2005-10-26 2005-10-26     4\n 7 A2     -0.1   D     2006-02-01 0010…  10560 0039… 2006-02-01 2006-02-01     5\n 8 AA0A    0.107 D     2003-05-08 0010…  10656 0044… 2003-05-08 2003-05-08     1\n 9 AA0A    0.129 D     2003-11-06 0010…  10656 0044… 2003-11-06 2003-11-06     1\n10 AA0A    0.127 D     2004-02-11 0010…  10656 0044… 2004-02-11 2004-02-11     1\n# … with 130,797 more rows, 11 more variables: median <dbl>, mean <dbl>,\n#   mean_days <dbl>, car_short <dbl>, car_long <dbl>, date_minus5 <date>,\n#   date <date>, prc <dbl>, market_value <dbl>, surprise <dbl>, weekday <ord>,\n#   and abbreviated variable name ¹​anndats_act\n\nsaveRDS(main, here(\"data\", \"freaky_friday\", \"main.RDS\"))\n\n\n\nOverview of the datasets\n\n\n\nFile\nDescription\n\n\n\n\nearn_ann.RDS\nThe information on the earnings announcements\n\n\nanalyst.RDS\nThe analyst estimates data\n\n\nmain.RDS\nThe main dataset to replicate the paper\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nDellavigna, Stefano, and Joshua M. Pollet. 2009. “Investor Inattention and Friday Earnings Announcements.” The Journal of Finance 64 (2): 709–49. https://doi.org/10.1111/j.1540-6261.2009.01447.x.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 1–23. https://doi.org/10.18637/jss.v059.i10.\n\nFootnotes\n\n\nR is fundamentally a programming language that is build around functions. The tidyverse partially works around that by making tibbles the primary object. Nevertheless, when you need to do some more advanced programming, creating functions is quite natural in R.↩︎\nFor comparison on my 2020 Mac Mini, it takes about 1.5 seconds for 100 announcements and 4.0 seconds for 10000 announcements. On my 2014 Macbook pro, that is respectively 4.3 seconds and 11.2 seconds.↩︎"
  },
  {
    "objectID": "freaky_friday/descriptive.html",
    "href": "freaky_friday/descriptive.html",
    "title": "Descriptive statistics",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(here)\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\ntheme_set(theme_cowplot(font_size = 18))\ni_am(\"freaky_friday/descriptive.qmd\")\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\n\n\nmain <- readRDS(here(\"data\", \"freaky_friday\", \"main.RDS\")) %>%\n  mutate(group = if_else(weekday == \"Fri\", \"Friday\", \"Non-Friday\"),\n         year = year(anndat))\nglimpse(main)\n\nRows: 130,807\nColumns: 23\n$ ticker       <chr> \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"AA0A\", \"AA0A\",…\n$ actual       <dbl> -0.0800, -0.0400, -0.1100, -0.1100, -0.0500, -0.0700, -0.…\n$ pdf          <chr> \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D…\n$ anndats_act  <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ gvkey        <chr> \"001081\", \"001081\", \"001081\", \"001081\", \"001081\", \"001081…\n$ permno       <dbl> 10560, 10560, 10560, 10560, 10560, 10560, 10560, 10656, 1…\n$ cusip        <chr> \"00392410\", \"00392410\", \"00392410\", \"00392410\", \"00392410…\n$ rdq          <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ anndat       <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ N            <int> 4, 1, 2, 3, 2, 4, 5, 1, 1, 1, 1, 2, 1, 1, 3, 2, 3, 4, 3, …\n$ median       <dbl> -0.07425, -0.09000, -0.08965, -0.05740, -0.03700, -0.1061…\n$ mean         <dbl> -0.0726250, -0.0900000, -0.0896500, -0.0680000, -0.037000…\n$ mean_days    <dbl> 11.500000, 21.000000, 8.000000, 6.666667, 13.500000, 7.00…\n$ car_short    <dbl> -0.053110221, 0.097290996, 0.036461999, -0.063605082, -0.…\n$ car_long     <dbl> -0.33518052, 0.01028760, -0.20959886, 0.05661849, -0.1836…\n$ date_minus5  <date> 2006-04-21, 2004-10-16, 2005-01-21, 2005-04-22, 2005-07-…\n$ date         <date> 2006-04-21, 2004-10-15, 2005-01-21, 2005-04-22, 2005-07-…\n$ prc          <dbl> 4.28, 5.63, 5.89, 4.53, 5.00, 3.26, 4.02, 16.75, 15.66, 1…\n$ market_value <dbl> 1883949.1, 2478185.3, 2592630.7, 1993992.8, 2200875.0, 14…\n$ surprise     <dbl> -0.0013434579, 0.0088809945, -0.0034550086, -0.0116114785…\n$ weekday      <ord> Wed, Thu, Wed, Wed, Wed, Wed, Wed, Thu, Thu, Wed, Thu, Fr…\n$ group        <chr> \"Non-Friday\", \"Non-Friday\", \"Non-Friday\", \"Non-Friday\", \"…\n$ year         <dbl> 2006, 2004, 2005, 2005, 2005, 2005, 2006, 2003, 2003, 200…"
  },
  {
    "objectID": "freaky_friday/descriptive.html#quantiles",
    "href": "freaky_friday/descriptive.html#quantiles",
    "title": "Descriptive statistics",
    "section": "Quantiles",
    "text": "Quantiles\n\nquantiles <- main %>%\n  mutate(sign = case_when(surprise > 0 ~ \"positive\",\n                          surprise < 0 ~ \"negative\",\n                          surprise == 0 ~ \"zero\")) %>%\n  mutate(\n    quintile = ntile(surprise, 5),\n    .by = c(sign, year)) %>%\n  mutate(\n    quantile = case_when(sign == \"positive\" ~ 6 + quintile,\n                         sign == \"negative\" ~ quintile,\n                         sign == \"zero\" ~ 6\n                         )\n  ) %>%\n  glimpse()\n\nRows: 130,807\nColumns: 26\n$ ticker       <chr> \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"A2\", \"AA0A\", \"AA0A\",…\n$ actual       <dbl> -0.0800, -0.0400, -0.1100, -0.1100, -0.0500, -0.0700, -0.…\n$ pdf          <chr> \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D…\n$ anndats_act  <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ gvkey        <chr> \"001081\", \"001081\", \"001081\", \"001081\", \"001081\", \"001081…\n$ permno       <dbl> 10560, 10560, 10560, 10560, 10560, 10560, 10560, 10656, 1…\n$ cusip        <chr> \"00392410\", \"00392410\", \"00392410\", \"00392410\", \"00392410…\n$ rdq          <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ anndat       <date> 2006-04-26, 2004-10-21, 2005-01-26, 2005-04-27, 2005-07-…\n$ N            <int> 4, 1, 2, 3, 2, 4, 5, 1, 1, 1, 1, 2, 1, 1, 3, 2, 3, 4, 3, …\n$ median       <dbl> -0.07425, -0.09000, -0.08965, -0.05740, -0.03700, -0.1061…\n$ mean         <dbl> -0.0726250, -0.0900000, -0.0896500, -0.0680000, -0.037000…\n$ mean_days    <dbl> 11.500000, 21.000000, 8.000000, 6.666667, 13.500000, 7.00…\n$ car_short    <dbl> -0.053110221, 0.097290996, 0.036461999, -0.063605082, -0.…\n$ car_long     <dbl> -0.33518052, 0.01028760, -0.20959886, 0.05661849, -0.1836…\n$ date_minus5  <date> 2006-04-21, 2004-10-16, 2005-01-21, 2005-04-22, 2005-07-…\n$ date         <date> 2006-04-21, 2004-10-15, 2005-01-21, 2005-04-22, 2005-07-…\n$ prc          <dbl> 4.28, 5.63, 5.89, 4.53, 5.00, 3.26, 4.02, 16.75, 15.66, 1…\n$ market_value <dbl> 1883949.1, 2478185.3, 2592630.7, 1993992.8, 2200875.0, 14…\n$ surprise     <dbl> -0.0013434579, 0.0088809945, -0.0034550086, -0.0116114785…\n$ weekday      <ord> Wed, Thu, Wed, Wed, Wed, Wed, Wed, Thu, Thu, Wed, Thu, Fr…\n$ group        <chr> \"Non-Friday\", \"Non-Friday\", \"Non-Friday\", \"Non-Friday\", \"…\n$ year         <dbl> 2006, 2004, 2005, 2005, 2005, 2005, 2006, 2003, 2003, 200…\n$ sign         <chr> \"negative\", \"positive\", \"negative\", \"negative\", \"negative…\n$ quintile     <int> 3, 5, 2, 1, 3, 5, 2, 3, 3, 5, 2, 5, 2, 4, 5, 5, 2, 5, 1, …\n$ quantile     <dbl> 3, 11, 2, 1, 3, 11, 2, 9, 9, 5, 2, 11, 2, 10, 11, 11, 2, …\n\n\nThis is a quick version of Figure 1a. It can be further cleaned up with a better axis labels. It shows the main results from Dellavigna and Pollet (2009) that the market reaction is subdued on Fridays.\n\nggplot(quantiles,\n       aes(y = car_short, x = quantile, group = group, colour = group)) +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = .2) +\n  stat_summary(fun.y = mean, geom = \"line\") +\n  scale_color_grey()\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\nThis is how I would program Figure 1a and b together. It’s a good example of how using pivot_longer can make your life easier. In this case, if we need to plot multiple similar variables.\n\nquantiles %>%\n  pivot_longer(c(car_short, car_long), values_to = \"car\", names_to = \"window\") %>%\n  mutate(fig_name = if_else(window == \"car_short\", \"Figure 1a\", \"Figure 1b\")) %>%\n  ggplot(aes(y = car, x = quantile, group = group, colour = group)) +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = .2) +\n  stat_summary(fun = mean, geom = \"line\") +\n  scale_color_grey() +\n  facet_wrap(~ fig_name, nrow = 2)"
  },
  {
    "objectID": "freaky_friday/regressions.html",
    "href": "freaky_friday/regressions.html",
    "title": "Regressions",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(here)\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package\n\nlibrary(fixest)\nlibrary(modelsummary)\ngof_omit <- \"Adj|RMS|IC\"\ni_am(\"freaky_friday/regressions.qmd\")\n\nhere() starts at /Users/stijn/Dropbox/Teaching/lecturenotes/method_package"
  },
  {
    "objectID": "freaky_friday/regressions.html#table-2",
    "href": "freaky_friday/regressions.html#table-2",
    "title": "Regressions",
    "section": "Table 2",
    "text": "Table 2\nThe tables do not really replicate which is interesting to me. For a number of reasons.\n\nThe results are more consistent. I wonder whether I got rid of more outliers earlier. Remember I did end up with less observations. One interpretation is that I have cleaned the data better, the other is that I got rid of important, influential observations by being too strict when cleaning the data.\nThe results for the short term CAR are consistent with the figure. Friday market reactions to bottom quantile surprises are more positive than non-friday market reactions and the sign flips for top quantile surprises.\nI also lose substantially more observations due to the inclusion of the volatility measures. I do not know exactly why that is the case.\n\n\nPanel A: Short Term CAR\n\nsubset <- readRDS(here(\"data\", \"freaky_friday\", \"subset.RDS\"))\n#| label: table2a\nmodel1a <- feols(car_short ~ friday * top,\n                 cluster = \"anndat\",\n                 data = subset)\nmodel2a <- feols(car_short ~ friday * top | (year[top] + month[top] + size_decile[top]),\n                 cluster = \"anndat\",\n                 data = subset)\n\nThe variable 'top' has been removed because of collinearity (see $collin.var).\n\nmodel3a <- feols(car_short ~ friday * top | (year[top] + month[top] + size_decile[top] + vol_decile[top]),\n                 cluster = \"anndat\",\n                 data = subset)\n\nNOTE: 6,841 observations removed because of NA values (Fixed-effects: 6,841).\nThe variable 'top' has been removed because of collinearity (see $collin.var).\n\nmsummary(list(model1a, model2a, model3a), gof_omit = gof_omit, stars = TRUE)\n\n\n\n \n  \n      \n     (1) \n      (2) \n      (3) \n  \n \n\n  \n    (Intercept) \n    −0.036*** \n     \n     \n  \n  \n     \n    (0.001) \n     \n     \n  \n  \n    friday \n    0.014*** \n    0.012*** \n    0.013** \n  \n  \n     \n    (0.003) \n    (0.003) \n    (0.004) \n  \n  \n    top \n    0.061*** \n     \n     \n  \n  \n     \n    (0.002) \n     \n     \n  \n  \n    friday × top \n    −0.023*** \n    −0.020*** \n    −0.021*** \n  \n  \n     \n    (0.004) \n    (0.004) \n    (0.005) \n  \n  \n    Num.Obs. \n    22494 \n    22494 \n    15653 \n  \n  \n    R2 \n    0.086 \n    0.095 \n    0.110 \n  \n  \n    R2 Within \n     \n    0.001 \n    0.001 \n  \n  \n    Std.Errors \n    by: anndat \n    by: anndat \n    by: anndat \n  \n  \n    FE: size_decile \n     \n    X \n    X \n  \n  \n    FE: year \n     \n    X \n    X \n  \n  \n    FE: month \n     \n    X \n    X \n  \n  \n    FE: vol_decile \n     \n     \n    X \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\n\n\nPanel B: Long Term CAR\n\nmodel1b <- feols(car_long ~ friday * top,\n                 cluster = \"anndat\",\n                 data = subset)\nmodel2b <- feols(car_long ~ friday * top | (year[top] + month[top] + size_decile[top]),\n                 cluster = \"anndat\",\n                 data = subset)\n\nThe variable 'top' has been removed because of collinearity (see $collin.var).\n\nmodel3b <- feols(car_long ~ friday * top | (year[top] + month[top] + size_decile[top] + vol_decile[top]),\n                 cluster = \"anndat\",\n                 data = subset)\n\nNOTE: 6,841 observations removed because of NA values (Fixed-effects: 6,841).\nThe variable 'top' has been removed because of collinearity (see $collin.var).\n\nmsummary(list(model1b, model2b, model3b), gof_omit = gof_omit, stars = TRUE)\n\n\n\n \n  \n      \n     (1) \n      (2) \n      (3) \n  \n \n\n  \n    (Intercept) \n    −0.022*** \n     \n     \n  \n  \n     \n    (0.005) \n     \n     \n  \n  \n    friday \n    −0.012 \n    −0.012 \n    −0.022 \n  \n  \n     \n    (0.013) \n    (0.013) \n    (0.015) \n  \n  \n    top \n    0.037*** \n     \n     \n  \n  \n     \n    (0.004) \n     \n     \n  \n  \n    friday × top \n    0.041** \n    0.043** \n    0.052** \n  \n  \n     \n    (0.015) \n    (0.014) \n    (0.017) \n  \n  \n    Num.Obs. \n    22494 \n    22494 \n    15653 \n  \n  \n    R2 \n    0.006 \n    0.035 \n    0.041 \n  \n  \n    R2 Within \n     \n    0.001 \n    0.001 \n  \n  \n    Std.Errors \n    by: anndat \n    by: anndat \n    by: anndat \n  \n  \n    FE: size_decile \n     \n    X \n    X \n  \n  \n    FE: year \n     \n    X \n    X \n  \n  \n    FE: month \n     \n    X \n    X \n  \n  \n    FE: vol_decile \n     \n     \n    X \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001"
  },
  {
    "objectID": "freaky_friday/regressions.html#table-3",
    "href": "freaky_friday/regressions.html#table-3",
    "title": "Regressions",
    "section": "Table 3",
    "text": "Table 3\n\nmain_extra <- main %>%\n  mutate(log_size = log(market_value))  %>%\n  mutate(log_size_adj = log_size - mean(log_size, na.rm = T),\n         .by = c(quarter, year)) %>%\n  mutate(size_decile = ntile(log_size_adj, 10))\n\nmodel1 <- feols(car_short ~ friday * quantile,\n                cluster = \"anndat\",\n                data = main_extra)\nmodel2 <- feols(car_short ~ friday + friday : quantile\n                | (year[quantile] + month[quantile] + size_decile[quantile]),\n                cluster = \"anndat\",\n                data = main_extra)\nmodel3 <- feols(car_long ~ friday * quantile,\n                cluster = \"anndat\",\n                data = main_extra)\nmodel4 <- feols(car_long ~ friday  + friday : quantile\n                | (year[quantile] + month[quantile] + size_decile[quantile]),\n                cluster = \"anndat\",\n                data = main_extra)\n\nmsummary(list(model1, model2, model3, model4), gof_omit = gof_omit, stars = TRUE)\n\n\n\n \n  \n      \n     (1) \n      (2) \n      (3) \n      (4) \n  \n \n\n  \n    (Intercept) \n    −0.041*** \n     \n    −0.015*** \n     \n  \n  \n     \n    (0.001) \n     \n    (0.002) \n     \n  \n  \n    friday \n    0.016*** \n    0.014*** \n    −0.016* \n    −0.015* \n  \n  \n     \n    (0.002) \n    (0.002) \n    (0.008) \n    (0.007) \n  \n  \n    quantile \n    0.006*** \n     \n    0.003*** \n     \n  \n  \n     \n    (0.000) \n     \n    (0.000) \n     \n  \n  \n    friday × quantile \n    −0.002*** \n    −0.002*** \n    0.003** \n    0.003*** \n  \n  \n     \n    (0.000) \n    (0.000) \n    (0.001) \n    (0.001) \n  \n  \n    Num.Obs. \n    130807 \n    130807 \n    130807 \n    130807 \n  \n  \n    R2 \n    0.054 \n    0.057 \n    0.002 \n    0.015 \n  \n  \n    R2 Within \n     \n    0.000 \n     \n    0.000 \n  \n  \n    Std.Errors \n    by: anndat \n    by: anndat \n    by: anndat \n    by: anndat \n  \n  \n    FE: size_decile \n     \n    X \n     \n    X \n  \n  \n    FE: year \n     \n    X \n     \n    X \n  \n  \n    FE: month \n     \n    X \n     \n    X \n  \n\n\n + p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001"
  }
]